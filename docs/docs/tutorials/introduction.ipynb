{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a1aae78-88a6-4133-b905-7e46c8e3772f",
   "metadata": {},
   "source": [
    "# 🚀 LangGraph Quickstart\n",
    "\n",
    "In this tutorial, we will build a support chatbot in LangGraph that can:\n",
    "\n",
    "✅ **Answer common questions** by searching the web  \n",
    "✅ **Maintain conversation state** across calls  \n",
    "✅ **Route complex queries** to a human for review  \n",
    "✅ **Use custom state** to control its behavior  \n",
    "✅ **Rewind and explore** alternative conversation paths  \n",
    "\n",
    "We'll start with a **basic chatbot** and progressively add more sophisticated capabilities, introducing key LangGraph concepts along the way. Let’s dive in! 🌟\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, install the required packages and configure your environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f11d631-8679-4f28-822f-cdf1f2ddc21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langsmith langchain_anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "705d4020-6ee8-44cc-b1a5-8c34e7172fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTHROPIC_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c72cf-33f9-4a37-9634-6c93a7c28815",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Set up <a href=\"https://smith.langchain.com\">LangSmith</a> for LangGraph development</p>\n",
    "    <p style=\"padding-top: 5px;\">\n",
    "        Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph — read more about how to get started <a href=\"https://docs.smith.langchain.com\">here</a>. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c374e41-f9b7-439e-a520-6d8c853c5220",
   "metadata": {},
   "source": [
    "## Part 1: Build a Basic Chatbot\n",
    "\n",
    "We'll first create a simple chatbot using LangGraph. This chatbot will respond directly to user messages. Though simple, it will illustrate the core concepts of building with LangGraph. By the end of this section, you will have a built rudimentary chatbot.\n",
    "\n",
    "Start by creating a `StateGraph`. A `StateGraph` object defines the structure of our chatbot as a \"state machine\". We'll add `nodes` to represent the llm and functions our chatbot can call and `edges` to specify how the bot should transition between these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58df974-7579-4f25-9d91-66389b94eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c08c41da-0855-49d3-9a3d-b7eb94413367",
   "metadata": {},
   "source": [
    "Our graph can now handle two key tasks:\n",
    "\n",
    "1. Each `node` can receive the current `State` as input and output an update to the state.\n",
    "2. Updates to `messages` will be appended to the existing list rather than overwriting it, thanks to the prebuilt [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages) function used with the `Annotated` syntax.\n",
    "\n",
    "------\n",
    "\n",
    "!!! tip \"Concept\"\n",
    "\n",
    "    When defining a graph, the first step is to define its `State`. The `State` includes the graph's schema and [reducer functions](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) that handle state updates. In our example, `State` is a `TypedDict` with one key: `messages`. The [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.message.add_messages) reducer function is used to append new messages to the list instead of overwriting it. Keys without a reducer annotation will overwrite previous values. Learn more about state, reducers, and related concepts in [this guide](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.message.add_messages).\n",
    "\n",
    "---------\n",
    "\n",
    "\n",
    "Next, add a \"`chatbot`\" node. Nodes represent units of work. They are typically regular python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c9137-8261-42ea-8e83-3590981d23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c1dcd9-fb86-4649-81b4-ff6ce20a2e46",
   "metadata": {},
   "source": [
    "**Notice** how the `chatbot` node function takes the current `State` as input and returns a dictionary containing an updated `messages` list under the key \"messages\". This is the basic pattern for all LangGraph node functions.\n",
    "\n",
    "The `add_messages` function in our `State` will append the llm's response messages to whatever messages are already in the state.\n",
    "\n",
    "Next, add an `entry` point. This tells our graph **where to start its work** each time we run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e331e10d-ebcf-4144-9bd3-999b4d656dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499c318-d1e6-46fa-a652-8f9e65313355",
   "metadata": {},
   "source": [
    "Similarly, set a `finish` point. This instructs the graph **\"any time this node is run, you can exit.\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f0929-3591-4852-b2d3-eaadde40662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9b88c-2c53-4d95-8eb1-d544a8946f65",
   "metadata": {},
   "source": [
    "Finally, we'll want to be able to run our graph. To do so, call \"`compile()`\" on the graph builder. This creates a \"`CompiledGraph`\" we can use invoke on our state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb67a01-cf5c-4625-8c07-6e8c0af50fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c39407b-d6f6-48a4-b1f6-31fc7f88b275",
   "metadata": {},
   "source": [
    "You can visualize the graph using the `get_graph` method and one of the \"draw\" methods, like `draw_ascii` or `draw_png`. The `draw` methods each require additional dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9403859a-f25a-46b4-a672-46a93f8a3cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGsAAADqCAIAAAAqMSwmAAAAAXNSR0IArs4c6QAAFt9JREFUeJztnXtgE1W6wE8ySZp3miZt+n5T+qQgBQELLbY8LS21CgJlAZWVpcvuvbgruysuuF653Iou966r7F2KrlBFWAWsIgWFIm+oPGzpi77pg7Z5v1+T3D/CrSxNMpNOQk7r/P7rzJzpl1/OTM6cc+Z8FLvdDkgIQPV3AGMe0iBRSINEIQ0ShTRIFNIgUWgEy2vkFpXMotegejVqtdhttjHQNkJogEajsvkIm0cThtLZXEISKKNrD8r6TW0/6DrqdAw2BdgpbB7C5iMsDs2GjgGDNDpFq7bq1aheYzUZbHQGNT6Dk5jJ5Yvoozibxwa1SuvFKqkdgEAxPS6DExLJHMV/hYr+DkN7nU4xYOYKabMKxAymZ3c2zwxeOymvv6iatUQ8cSrP81Bhp+686uKX0hlPiTJnB+Iv5YHBY+/3Jk7hps0QjDbCscH338hl98zzS0NxHo+3xla81jHlSeG41wcAmJofFJPMOfZ+L94Cdhzs3dou7TPiOXLccOem5uCubjxHYl/Fx97vnfKkMHoi2wvf75ii8Yq6t92Qv0Li/jAMg7Wn5CwukjZz/F+8Tqn9Rs7iYHx8d/dBrdJad0H1k9UHAMjKDzpzaMj9Me4MXqySzloi9nZUY4yZBaKLVVI3B7g0KOs32QEYl+0+j5iaJ5T2mYw6q6sDXBps+0EXKB7NU87oqK+vN5lM/iruHg6f1l6vd7XXpcGOOl1cBsdHMT1EVVXV2rVrDQaDX4pjEp/Bba/Tutrr3KBabglgUx/ZM++oq4+jIeG72ucgLp2jVVhddTu5MCiz+GgIr6ura8OGDdnZ2YsXL96xY4fNZquqqtq5cycAID8/Pysrq6qqCgAwMDCwbdu2/Pz8GTNmLF++/MSJE47iSqUyKytr//79W7duzc7OXr9+vdPiXsdqsaukFqe7nHeN6TUom4f4IpQ33nijs7Pz5Zdf1ul0tbW1VCr1iSeeKC0tPXDgwO7du7lcbnR0NADAarXevn37mWeeCQwMPH369NatW6OiotLS0hwnqaioePbZZ/fs2YMgiEQiGVnc67D5iF6NCkOc7HJhUI2y+T4x2NfXl5ycXFxcDAAoLS0FAAQFBUVGRgIA0tPTAwPvd4pEREQcPnyYQqEAAIqKivLz82tqaoYNZmRklJWVDZ9zZHGvw+HTdGrnP8cuf0noDJ8MACxevPjy5cvl5eVyudz9kS0tLZs3b164cGFxcTGKojKZbHjX9OnTfRGbGxhMqquHN+eamByqRuGyBUSEsrKyzZs3nzx5srCw8NChQ64Ou3bt2po1a8xm87Zt28rLywUCgc1mG97LYrF8EZsbVFILm+f8enW+lc2j6TU+MUihUFauXFlUVLRjx47y8vKkpKTJkyc7dj34Je/duzcyMnL37t00Gg2nMp9OX3Hzw+C8DnKFSADLJ1exo+XB4XA2bNgAAGhqahoWNDT04xOoUqlMSkpy6DObzXq9/sE6+BAji3sdjgDhCZ0/Xzivg0GSgKEes3LIHBjM8G4oW7Zs4XK5M2bMOH/+PAAgJSUFAJCZmYkgyK5duwoLC00mU0lJiaNdcuzYMYFAUFlZqVar29raXNWykcW9G3Nvq8FmBa7GT5Dt27c73aFRWHUqa1icl+84PT0958+fP3HihMFg2LRpU25uLgCAz+dLJJJTp06dO3dOrVYXFBRkZma2t7cfPHiwtrZ23rx5y5cvr66uTk5OFolEH330UXZ2dmpq6vA5Rxb3bsy3ziolsczQWOfPFy77B/vaDY1X1HlY/Ys/Bb6q6M8uEgtc9BK4HGwOj2ddPSG/26KPSnLeO61WqwsLC53uioyM7OnpGbk9Jyfn9ddfxx35KHnxxRdbW1tHbk9JSWlsbBy5PT09/d1333V1tsar6gAW1ZU+jD7qwbvGM4eGlr8c5XSvzWa7d++e85NSnJ+WxWIJhUJX/85bDA0NWSxOnsBcRcVgMMRil92gFa91rHglylVTBruX/7sjQ9FJ7Ni0R9RJAxu3L6v0anTa/CA3x2A0WeYUB5/9fEgtc/5QPb7pazM0XdO41wfwjHaajOieV1q9MYI4ljDoLH/7XRueI3GNF5tN6N9+36pVWQgHNjYY7DFW/LHdarXhORjvrA+DFv2kvHvBzyQRieN84Lj1lqb2pOK53+LtJfNs5tGZTwfVCssTS8TiiIDRRggvvW2GS1UySUzA7OJg/KU8nv3W3aS/UCWNTmZLophx6RyERvE8VLgwG23t9dp7nUZ5v3nmElFYrGePYaOcgdn2g7bluqajXjdxKo8eQOXwaRwBwmQjY2EKK0CoFL3GqlNbdWpUq7L0tBji07lJWdyY5NE02kZpcJjuJr1i0KxTW3Uq1GazW83eVIiiaF1d3XD3l7cIYFMd3c4cPiIKYxC8sxM16FO0Wm1BQUFNTY2/A3EHOZefKKRBosBu0NEFCzOwG3TaHwUVsBv03RCwt4DdoFKp9HcIGMBuMDw83N8hYAC7wb6+Pn+HgAHsBjMyMvwdAgawG6yrq/N3CBjAbhB+YDfoZhQNEmA3KJW6exMBBmA3GBzsQXexX4DdoE9nZHkF2A3CD+wGExMT/R0CBrAbdDqHCCpgNwg/sBt8cKYlnMBusKGhwd8hYAC7QfiB3SDZN0MUsm9m/AO7QXK0kyjkaOf4B3aD5HgxUcjxYqJMmDDB3yFgALvBO3fu+DsEDGA3CD+wGwwNxbsWpb+A3aCrlx/hAXaD6enp/g4BA9gN1tfX+zsEDGA3SNZBopB1kChRUc7fsIcHGN/IWb9+fV9fH41Gs9lsUqlULBZTqVSLxXL8+HF/h+YEGOvgqlWr1Gp1b29vf3+/xWLp7+/v7e1FEJ+spEYcGA3m5uY+9Dhst9uhHTCB0SAAYPXq1Wz2jy8MhoWFPffcc36NyCWQGpw7d25cXNzwPTozM3PSpEn+Dso5kBoEAKxbt87RvSoWi6GtgFAbzM3NjY+PdwwZQ3sT9CxPk1GPyvrMJqPLVey8ztL5L5kUny7OXdder3tk/5TFoYrDA+gBeOsWrvag3W6v/uhed5MhYgIbtUDXfvQuqNU20GVMnMzNX4lr1TZsgxaT7bO/9EzOFUVM+AmtHXXnhrq7UVO0Idyxmq4bsA1+8lb3zCUSUdg4XB7FPZ0Nms46zZKfY7zYh3G1N9Wqw+PZP0F9AIDYVB6DhXQ3Y9yCMQwO3jUxiSXEG9PQAxBpn9n9MRgGzQYbL+jRZYiAjcAQhlGDuj8Gy6DRZn90rRfoQC12C1bbA94W9ViBNEgU0iBRSINEIQ0ShTRIFNIgUUiDRCENEoU0SBTSIFEekcE7rc1z87IuXTrnacGGxn9JJ7n1jy+/tKHU05OgKFpXd9PTUjiBug6eqK4q++Vao5FoOsm33n7jnd07vBTUw0Bt0FvpJM2+TEvp/d5To9G4/8DeM2dODkkHJZKw+fOeWrVynWNXR2fbwUMfNTc3REZG/3rTloyMyQCAwcGBig/eu3Llgk6njYqKWbliXX7eQkcF3P3fOwEAS5/OBwBseWXbwgVLAAA6vW7b9leu37jKYATkPbnwhec3BgTc70I/efKryk8+6OvrEYnETy0uXrVyHZVK3Vm+/UzNKQDA3LwsAMDhT78Wi725ho2XDaIo+odX/62u/ubTxc8lJiR1drXf7ekanjR0oLJi2bOrFy0s/PiTD199bfPHB77gcrlW1NrUdLuo8BkBP/C786ff3LE1IiIqJTnt8elPLHu29NDhA//55m4OhxsZeX+h/IGB/pkzZpdtfPnatUuH/1nZ23f3zTfeAQBUV3+5s3x7Xt7CF57f2NBQt++D9wEAq0tfKF35/NDgQH9/7+9/9ycAgEDg5ZekvGzw7Hff3rhZ+9vfvLZ4UdHIvb/etGXBggIAQEx03MZfrv3++pWcOXnhYREf7rufYHLRoqLikvwLF2pSktOEwqDw8EgAQEpK+oMfOz4usWzjZgDAwgVLxOKQQ4cP3Lp1fdKkKXv3/TUjY/LWP/wHAGDO7Cc1GvXBT/9R8vSKyMhogSBQrpA5qrzX8fJ98Oq1iwEBAQvmO8/WxeffTwkfG5sAABgaGnD82drW8uprm59ZtnD1mmIUReVymdPiIyleuhwAcONmbU9Pt1Q6NGf2k8O7pk2bqdfre3q7CX8mDLxsUCGXiUXBmHP9qFSq45IHAFy/cW1j2RqL2fzKb7e9vq2czxfgH1hw3NF0Oq1WpwUABAb+mM+Gx+MDAKRDg8Q+EDZevoq5XJ5cgbcGOdi/f294eOSON/8/wSTz4dQMbka0lUoFAEAoDAoJlgAAVKofX2NUKOTDHn2ak9LLdXDKlGkGg+Hb09XDW6xWjPyfKrUyMeGBBJOGHxNMOmxKpS4XLzt79hsAwGOPTReJxKGSsKtXLzy4i8lkJiZOBAAwmSy5XOYmbyURvFwH5+UvPnrs0M7/2tbUdDsxIam9o/X761f+d0+lmyKTJ2dVV1cd//oYnyc4/FmlRqPu7Giz2+0UCiUtPRNBkHff27VoQaHJbCpcUgIAaGu/89f33klImNDc3FD15ec5c/KSJ6YCANaueWln+fa3dr0xbdrM69evnr9Qs+ZnP3ek9Myc9NjXJ7545887MtInSyRhkydP9eJHdpl10sGdG9rAkACBGG/2ThqNlpMzT6VS1pw9deFijUqtzM2Zl5qaoVIpq778PO/JhVFRMY474IHKfVlZM9LTMtNSM7u62j8/cvDmrdrcnHlPL11++kz1hAnJYWERfB4/OFhSU3Pq0qVzGo16wYKC02dOzs6e29R0+6vjR/rv9S0pKPnVplcct93ExCShMOj0mZNfn/hCqZCvXLmudNXzjp/4+PhEjUb17ekTt364HhUZnZKC9x0Vaa/JYkJjU91NGMKYN3N8X39MGj96VKlPxgFNV1V6tTmnxF0LHOqnujEBaZAopEGikAaJQhokCmmQKKRBopAGiUIaJAppkCikQaKQBolCGiQKhkFOIB2M+QTFo4eKUNhcrBEL97s5POrQXaNXoxpLDHQZeCKMTmgMg9EpbK0c46WecYxeY4lKwshujGEwJJIZnsA8f2TAq4GNDb79pD9jloDDx6iDuN4vrrugaqvTxSRzxRFM/K8uj1GMelTaa2y8oswuEselYXfO412xp7dV33hVo1WhysFHeFHb7SazeXhazKOBJ6QHSeiZuYFBElyjQzCueTQMmYX8JwFpkCiwG4R5nRQHsBsks2sQhcy2RhQy2xpRyPwkRCHzkxCFvA8ShbwPjn9gNzhx4kR/h4AB7Aabm5v9HQIGsBuEH9gNMplMf4eAAewGjUbYx7lgNygQCPwdAgawG1SpVP4OAQPYDcIP7AYjIyP9HQIGsBvs6enxdwgYwG4QfmA3SGadJAqZdXL8A7tBcrSTKORo5/gHdoPkOAlRyHESogiFQn+HgAHsBhUKhb9DwAB2g/ADu0Fy1gdRyFkfRElNTfV3CBjAbrChocHfIWAAu0GyDhKFrINESUtL83cIGMD4Rk5ZWZlcLqfT6SiKtrW1xcfH02g0FEUrK92twucvYMxFl5OT8/bbbzvWGAUAtLS0+HQRS4LAeBUvW7YsKirqoY3Tp0/3UzgYwGgQAFBaWvrgC4l8Pn/FihV+jcglkBpcunRpRETE8J8TJkyYM2eOXyNyCaQGAQArVqxwVEOBQFBa6nE+iEcGvAaLi4sd1TAhIWH27Nn+DsclPvkt1qutKEa+UFwsL1lbUVGxvGStRoGxJDMeaDQKi4excMco8E57cKDL2F6vk/Vb+jsMJj0qDGUatV74zN6FxqBq5GYmBwlLYIVEMOLTOaJwL7w9T9TgD+eUjde0RoOdE8Tmitg0BkIL8P737C3sdrvVjFpNqFaq08n0AhE9ZTo3eRqfyDlHb7Dluua7I1J+CEcYLaAzYGyZY2I2WuWdCrPelFMsjnG76LQbRmnwqw8G9XoQGC6gM8ekuwcxas2aAbU4jDa3RDSK4qMxeHDXXZaQKwgnVPlhQ96tQIC56CWMvPcj8djgkff66Hw+V/RwBodxgKJPzWVa5q0K8aiUZ+3BI3/tpfO541IfAEAYztcZ6acqPVvgyQOD549JAYPJFY3nNfoDw/lKBbh51oNBarwGB7uNbXV6YaSX00RBSHCC+Gq1UqfG257Fa/DcUZkoNgjHgeMBSaLw/FEpzoNxGexu1pstlPF6+xuJIIw3eNcs68eVJxCXwVvfqdgiLuHAfMKfygv+eWyn10/LFnPrLqjxHInLYFejjh+CsZDhOIMXzGmv0+E5EttgZ4MuUMJypOv56cBg0SgIVdqHfSFjP5MN3jUyBb66A7a2f3/81Ht991p43KDEuKxF837B54kBAFvfzCtZsqW+saah+QKLyZ0xrXj+3BcdRVAU/aam4nLtUbPZkBA/1WLx1euznCDmQJdRjNV/g10H1TIrFfFJR+ydtmt//+hXkpC4ZUtfnTNrZXvnjT0flJnN940c/Pz18NCkjS/seSxz0cnTf29ovp9J7ciXb52qqUhOmlVc8BsGnWkwanwRGwCAQqHi6ZfEroNaJUrHWlF4dBz96u0ZWcXFBb9x/JmU+Phb/7O8ufVyRmouAGD6Y4V5OWsBAOGhSVe/P9bSejl14hM9fU2Xa4/k5axblL8BAJA15am2juu+iA0AgDBoWhX2gp/YBmkMKuKDLj+5on9gqEMqv3u59uiD25Wq+w9VDMb9WweCIAJ+iEo9BACoa6gBAMyZ9eO4HYXiq4EKOhMBOBbjxjZotdhsJtTrN0KNVgYAmDf3xUmpcx/czuOJRx5MpdJsNhQAoFTeYzK5HPajePHdYrSyuNjdLtgGOQKaRueNUY9/hcXkAQAsFlNIcCz+UhyO0GjUWqxmOg1vEsJRYzWhvAjsiw/7EggMptl9kPEyWBwdKAi9dr3KZL6fph1FrVarxX2pyIhkAMCNH6rdH+Yl7LwgHHc5zCNCY5hNtXJRtJcvHAqFUrT43//xyZa//O2FmdOfttnQ2hvHp05e+OA9biSZafnf1Oz77NjOewPtEWFJnXfr1BqXeVEJohnSh8Vhf2rsOhiVxNbITDbU+9UwIzX3+dJ3EIT+xfE/f1OzTygMjY+d4r4IgiAvrt6dlPj4pWuffVn9FyqFymH7pLvIpLMgVCDEsSQ1rj7qr/bdswBWYBikj8a+QNqpkoSis4vdZex0gGuc6LG5glMfS90YbG69sv/TP4zcTqcFWKzOH4w2rd8rCYnD89/x0Nh8ofKffxy53W63A2B32uL5xbr3IsJdLoum7FXPXx7hau+D4B0nOfp+H5XNc9W/YDYbtTr5yO1Wq4VGozstIuCHIIjXxvlcBWCz2ex2u9Os6HxesKvYFD1qPteStwLXgAleg7J7pqq/D8Rm4fpaxjot57rWbI0JYON6jsDboBeFBqRM50rbnXzP44z+psHsIjFOfZ6NND2+IIjFRJX9vnqShwFZlzI8hpb6uAdD4R6PFx//cMCEMoXh4/B3eahDGRoJZhd6NnPB48fyxWslFLNO1q30tCDkDLbKBHyrp/pGP2/m/DFpX5eVF8pn8R5p+hVfoFMY9VJ14iTWlNzRNM5HP3erq1H/3REpwqAHxQQyuT5/zvcFBrVZ1iGnM+w5JaLQmFF2PxGdP9hyXVN3UaMYMPOC2Rwxm0ZH6AEIQod0CqFj8qDVYtUM6jVD+tBY5qRsfuxo57058M4cVpXM0lGnu9dtGug2GrUoi0fTa6Cbw0qnU1GrjcmlhcYyw2MD4jI4mHnA8OCTt8KsZjuKQvcKEo1OQWjeH3GE8b26sQW8b0OMFUiDRCENEoU0SBTSIFFIg0T5P/3JQlLZOAxJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98097a3-a126-4081-b21e-697ec1185fff",
   "metadata": {},
   "source": [
    "Now let's run the chatbot! \n",
    "\n",
    "**Tip:** You can exit the chat loop at any time by typing \"quit\", \"exit\", or \"q\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a385b06-8d34-4a2d-aded-1cf4bb0ca590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, stateful AI applications that go beyond simple query-response interactions.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e1cdb5-869a-41ea-9dab-e28cfc524499",
   "metadata": {},
   "source": [
    "**Congratulations!** You've built your first chatbot using LangGraph. This bot can engage in basic conversation by taking user input and generating responses using an LLM. You can inspect a [LangSmith Trace](https://smith.langchain.com/public/7527e308-9502-4894-b347-f34385740d5a/r) for the call above at the provided link.\n",
    "\n",
    "However, you may have noticed that the bot's knowledge is limited to what's in its training data. In the next part, we'll add a web search tool to expand the bot's knowledge and make it more capable.\n",
    "\n",
    "Below is the full code for this section for your reference:\n",
    "\n",
    "<details>\n",
    "<summary>Full Code</summary>\n",
    "    <pre>\n",
    "        \n",
    "```python\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "graph = graph_builder.compile()\n",
    "```\n",
    "\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c5d4a-3134-413c-81fe-dd9752fbeb66",
   "metadata": {},
   "source": [
    "## Part 2: 🛠️ Enhancing the Chatbot with Tools\n",
    "\n",
    "To handle queries our chatbot can't answer \"from memory\", we'll integrate a web search tool. Our bot can use this tool to find relevant information and provide better responses.\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "Before we start, make sure you have the necessary packages installed and API keys set up:\n",
    "\n",
    "First, install the requirements to use the [Tavily Search Engine](https://python.langchain.com/docs/integrations/tools/tavily_search/), and set your [TAVILY_API_KEY](https://tavily.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7451151f-41fc-4af0-9359-024ae51b7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U tavily-python langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c52923c-5665-4f8c-a1ba-9799e369c49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAVILY_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591ce9ba-c431-4165-b815-25c944ef7cdb",
   "metadata": {},
   "source": [
    "Next, define the tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35c8978e-c07d-4dd0-a97b-0ce3a723eea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141',\n",
       "  'content': 'Nodes: Nodes are the building blocks of your LangGraph. Each node represents a function or a computation step. You define nodes to perform specific tasks, such as processing input, making ...'},\n",
       " {'url': 'https://saksheepatil05.medium.com/demystifying-langgraph-a-beginner-friendly-dive-into-langgraph-concepts-5ffe890ddac0',\n",
       "  'content': 'Nodes (Tasks): Nodes are like the workstations on the assembly line. Each node performs a specific task on the product. In LangGraph, nodes are Python functions that take the current state, do some work, and return an updated state. Next, we define the nodes, each representing a task in our sandwich-making process.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"What's a 'node' in LangGraph?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f503f02-d23d-42e8-9b5d-eb2681b242f4",
   "metadata": {},
   "source": [
    "The results are page summaries our chat bot can use to answer questions.\n",
    "\n",
    "\n",
    "Next, we'll start defining our graph. The following is all **the same as in Part 1**, except we have added `bind_tools` on our LLM. This lets the LLM know the correct JSON format to use if it wants to use our search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5af88b-47d2-43bf-9a2c-6c07506b1732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e84cfc-b1b2-48e3-8550-152a408c3926",
   "metadata": {},
   "source": [
    "Next we need to create a function to actually run the tools if they are called. We'll do this by adding the tools to a new node.\n",
    "\n",
    "Below, we implement a `BasicToolNode` that checks the most recent message in the state and calls tools if the message contains `tool_calls`. It relies on the LLM's `tool_calling` support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers.\n",
    "\n",
    "We will later replace this with LangGraph's prebuilt [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode) to speed things up, but building it ourselves first is instructive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1fc14-cd91-4cd4-9f2e-1d007f8beafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b049afc4-7757-40ba-8e00-589d378e816d",
   "metadata": {},
   "source": [
    "With the tool node added, we can define the `conditional_edges`. \n",
    "\n",
    "Recall that **edges** route the control flow from one node to the next. **Conditional edges** usually contain \"if\" statements to route to different nodes depending on the current graph state. These functions receive the current graph `state` and return a string or list of strings indicating which node(s) to call next.\n",
    "\n",
    "Below, call define a router function called `route_tools`, that checks for tool_calls in the chatbot's output. Provide this function to the graph by calling `add_conditional_edges`, which tells the graph that whenever the `chatbot` node completes to check this function to see where to go next. \n",
    "\n",
    "The condition will route to `tools` if tool calls are present and `END` if not.\n",
    "\n",
    "Later, we will replace this with the prebuilt [tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition) to be more concise, but implementing it ourselves first makes things more clear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d662df94-66ac-4c6c-92f0-4c93620f1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_tools(\n",
    "    state: State,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aa67c2-dd1b-4bf2-8c64-eea44296d15f",
   "metadata": {},
   "source": [
    "**Notice** that conditional edges start from a single node. This tells the graph \"any time the '`chatbot`' node runs, either go to 'tools' if it calls a tool, or end the loop if it responds directly. \n",
    "\n",
    "Like the prebuilt `tools_condition`, our function returns the `END` string if no tool calls are made. When the graph transitions to `END`, it has no more tasks to complete and ceases execution. Because the condition can return `END`, we don't need to explicitly set a `finish_point` this time. Our graph already has a way to finish!\n",
    "\n",
    "Let's visualize the graph we've built. The following function has some additional dependencies to run that are unimportant for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b49509c-9d97-457c-a76a-c495fb30ccbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59593ef-5073-4279-931e-828dae971f23",
   "metadata": {},
   "source": [
    "Now we can ask the bot questions outside its training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "051dc374-67cc-4371-9dd1-221e07593148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{'text': \"To provide you with accurate and up-to-date information about LangGraph, I'll need to search for the latest details. Let me do that for you.\", 'type': 'text'}, {'id': 'toolu_01Q588CszHaSvvP2MxRq9zRD', 'input': {'query': 'LangGraph AI tool information'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Assistant: [{\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"LangGraph sets the foundation for how we can build and scale AI workloads \\u2014 from conversational agents, complex task automation, to custom LLM-backed experiences that 'just work'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution ...\"}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Overview. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures ...\"}]\n",
      "Assistant: Based on the search results, I can provide you with information about LangGraph:\n",
      "\n",
      "1. Purpose:\n",
      "   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It's particularly useful for creating agent and multi-agent workflows.\n",
      "\n",
      "2. Developer:\n",
      "   LangGraph is developed by LangChain, a company known for its tools and frameworks in the AI and LLM space.\n",
      "\n",
      "3. Key Features:\n",
      "   - Cycles: LangGraph allows the definition of flows that involve cycles, which is essential for most agentic architectures.\n",
      "   - Controllability: It offers enhanced control over the application flow.\n",
      "   - Persistence: The library provides ways to maintain state and persistence in LLM-based applications.\n",
      "\n",
      "4. Use Cases:\n",
      "   LangGraph can be used for various applications, including:\n",
      "   - Conversational agents\n",
      "   - Complex task automation\n",
      "   - Custom LLM-backed experiences\n",
      "\n",
      "5. Integration:\n",
      "   LangGraph works in conjunction with LangSmith, another tool by LangChain, to provide an out-of-the-box solution for building complex, production-ready features with LLMs.\n",
      "\n",
      "6. Significance:\n",
      "   LangGraph is described as setting the foundation for building and scaling AI workloads. It's positioned as a key tool in the next chapter of LLM-based application development, particularly in the realm of agentic AI.\n",
      "\n",
      "7. Availability:\n",
      "   LangGraph is open-source and available on GitHub, which suggests that developers can access and contribute to its codebase.\n",
      "\n",
      "8. Comparison to Other Frameworks:\n",
      "   LangGraph is noted to offer unique benefits compared to other LLM frameworks, particularly in its ability to handle cycles, provide controllability, and maintain persistence.\n",
      "\n",
      "LangGraph appears to be a significant tool in the evolving landscape of LLM-based application development, offering developers new ways to create more complex, stateful, and interactive AI systems.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da9e85-2e5d-49c2-8cbd-572cbdb89135",
   "metadata": {},
   "source": [
    "**Congrats!** You've created a conversational agent in langgraph that can use a search engine to retrieve updated information when needed. Now it can handle a wider range of user queries. To inspect all the steps your agent just took, check out this [LangSmith trace](https://smith.langchain.com/public/4fbd7636-25af-4638-9587-5a02fdbb0172/r).\n",
    "\n",
    "Our chatbot still can't remember past interactions on its own, limiting its ability to have coherent, multi-turn conversations. In the next part, we'll add **memory** to address this.\n",
    "\n",
    "\n",
    "The full code for the graph we've created in this section is reproduced below, replacing our `BasicToolNode` for the prebuilt [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode), and our `route_tools` condition with the prebuilt [tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition)\n",
    "\n",
    "<details>\n",
    "<summary>Full Code</summary>\n",
    "    <pre>\n",
    "\n",
    "```python\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile()\n",
    "```\n",
    "\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae45f2aa-396f-4f3f-848b-7750611617f8",
   "metadata": {},
   "source": [
    "## Part 3: Adding Memory to the Chatbot\n",
    "\n",
    "Our chatbot can now use tools to answer user questions, but it doesn't remember the context of previous interactions. This limits its ability to have coherent, multi-turn conversations.\n",
    "\n",
    "LangGraph solves this problem through **persistent checkpointing**. If you provide a `checkpointer` when compiling the graph and a `thread_id` when calling your graph, LangGraph automatically saves the state after each step. When you invoke the graph again using the same `thread_id`, the graph loads its saved state, allowing the chatbot to pick up where it left off. \n",
    "\n",
    "We will see later that **checkpointing** is _much_ more powerful than simple chat memory - it lets you save and resume complex state at any time for error recovery, human-in-the-loop workflows, time travel interactions, and more. But before we get too ahead of ourselves, let's add checkpointing to enable multi-turn conversations.\n",
    "\n",
    "To get started, create a `MemorySaver` checkpointer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6baafdf6-6803-4305-9381-9dc970468a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3d11a-1b42-4cbb-8e11-2a4294263d90",
   "metadata": {},
   "source": [
    "**Notice** we're using an in-memory checkpointer. This is convenient for our tutorial (it saves it all in-memory). In a production application, you would likely change this to use `SqliteSaver` or `PostgresSaver` and connect to your own DB.\n",
    "\n",
    "Next define the graph. Now that you've already built your own `BasicToolNode`, we'll replace it with LangGraph's prebuilt `ToolNode` and `tools_condition`, since these do some nice things like parallel API execution. Apart from that, the following is all copied from Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a51f1e-00de-4701-8931-de8cf19294ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a292dfe-764f-4561-90aa-71317d679d3e",
   "metadata": {},
   "source": [
    "Finally, compile the graph with the provided checkpointer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a06548bf-81fa-4436-b4c1-f68601fb4187",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df01805c-4458-4474-b13b-59ecfe228f12",
   "metadata": {},
   "source": [
    "Notice the connectivity of the graph hasn't changed since Part 2. All we are doing is checkpointing the `State` as the graph works through each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "761d15fb-d5e2-4d50-a630-126d77e77294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8265ef-e5b4-4c32-9856-5572b5652142",
   "metadata": {},
   "source": [
    "Now you can interact with your bot! First, pick a thread to use as the key for this conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be7b5abb-04ef-4d53-83d1-d4d3139cc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b1a5ee-7fa2-475c-a9db-749694b90ba9",
   "metadata": {},
   "source": [
    "Next, call your chat bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dba1b168-f8e0-496d-9bd6-37198fb4776e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi there! My name is Will.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Will! It's nice to meet you. How can I assist you today? Is there anything specific you'd like to know or discuss?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Hi there! My name is Will.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c6b470-5082-4c3e-b732-34de47c88735",
   "metadata": {},
   "source": [
    "**Note:** The config was provided as the **second positional argument** when calling our graph. It importantly is _not_ nested within the graph inputs (`{'messages': []}`).\n",
    "\n",
    "Let's ask a followup: see if it remembers your name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5447778-53d7-47f3-801b-f47bcf2185a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you'd like to talk about or any questions you have? I'm here to help with a wide range of topics or tasks.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Remember my name?\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be4cd8-f96f-4949-9d1f-48054502e5d0",
   "metadata": {},
   "source": [
    "**Notice** that we aren't using an external list for memory: it's all handled by the checkpointer! You can inspect the full execution in this [LangSmith trace](https://smith.langchain.com/public/29ba22b5-6d40-4fbe-8d27-b369e3329c84/r) to see what's going on.\n",
    "\n",
    "Don't believe me? Try this using a different config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4527cf9a-b191-4bde-858a-e33a74a48c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I apologize, but I don't have any previous context or memory of your name. As an AI assistant, I don't retain information from past conversations. Each interaction starts fresh. Could you please tell me your name so I can address you properly in this conversation?\n"
     ]
    }
   ],
   "source": [
    "# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeccbf0-ed74-4838-a7e9-31910d82b0b2",
   "metadata": {},
   "source": [
    "**Notice** that the **only** change we've made is to modify the `thread_id` in the config. See this call's [LangSmith trace](https://smith.langchain.com/public/51a62351-2f0a-4058-91cc-9996c5561428/r) for comparison. \n",
    "\n",
    "By now, we have made a few checkpoints across two different threads. But what goes into a checkpoint? To inspect a graph's `state` for a given config at any time, call `get_state(config)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0be77c25-1423-4f2d-9b2d-28530cc761a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='8c1ca919-c553-4ebf-95d4-b59a2d61e078'), AIMessage(content=\"Hello Will! It's nice to meet you. How can I assist you today? Is there anything specific you'd like to know or discuss?\", additional_kwargs={}, response_metadata={'id': 'msg_01WTQebPhNwmMrmmWojJ9KXJ', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 405, 'output_tokens': 32}}, id='run-58587b77-8c82-41e6-8a90-d62c444a261d-0', usage_metadata={'input_tokens': 405, 'output_tokens': 32, 'total_tokens': 437}), HumanMessage(content='Remember my name?', additional_kwargs={}, response_metadata={}, id='daba7df6-ad75-4d6b-8057-745881cea1ca'), AIMessage(content=\"Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you'd like to talk about or any questions you have? I'm here to help with a wide range of topics or tasks.\", additional_kwargs={}, response_metadata={'id': 'msg_01E41KitY74HpENRgXx94vag', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 444, 'output_tokens': 58}}, id='run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0', usage_metadata={'input_tokens': 444, 'output_tokens': 58, 'total_tokens': 502})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef7d06e-93e0-6acc-8004-f2ac846575d2'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content=\"Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you'd like to talk about or any questions you have? I'm here to help with a wide range of topics or tasks.\", additional_kwargs={}, response_metadata={'id': 'msg_01E41KitY74HpENRgXx94vag', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 444, 'output_tokens': 58}}, id='run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0', usage_metadata={'input_tokens': 444, 'output_tokens': 58, 'total_tokens': 502})]}}, 'step': 4, 'parents': {}}, created_at='2024-09-27T19:30:10.820758+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef7d06e-859f-6206-8003-e1bd3c264b8f'}}, tasks=())"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c106bd09-f155-4e15-9120-c60c834106e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.next  # (since the graph ended this turn, `next` is empty. If you fetch a state from within a graph invocation, next tells which node will execute next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f4998-6780-4cce-8f3c-9a5580888e3a",
   "metadata": {},
   "source": [
    "The snapshot above contains the current state values, corresponding config, and the `next` node to process. In our case, the graph has reached an `END` state, so `next` is empty.\n",
    "\n",
    "**Congratulations!** Your chatbot can now maintain conversation state across sessions thanks to LangGraph's checkpointing system. This opens up exciting possibilities for more natural, contextual interactions. LangGraph's checkpointing even handles **arbitrarily complex graph states**, which is much more expressive and powerful than simple chat memory.\n",
    "\n",
    "In the next part, we'll introduce human oversight to our bot to handle situations where it may need guidance or verification before proceeding.\n",
    "  \n",
    "Check out the code snippet below to review our graph from this section.\n",
    "\n",
    "<details>\n",
    "<summary>Full Code</summary>\n",
    "    <pre>\n",
    "\n",
    "```python\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "```\n",
    "</pre>\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1da240-ec9b-441f-9d47-44c6dc85d540",
   "metadata": {},
   "source": [
    "## Part 4: Human-in-the-loop\n",
    "\n",
    "Agents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended.\n",
    "\n",
    "LangGraph's [persistence](../../concepts/persistence) layer supports human-in-the-loop workflows, allowing execution to pause and resume based on user feedback. The primary interface to this functionality is the [interrupt](../../concepts/human_in_the_loop/#interrupt) function. Calling `interrupt` inside a node will pause execution. Execution can be resumed, together with new input from a human, by passing in a [Command](../../concepts/human_in_the_loop/#the-command-primitive). `interrupt` is ergonomically similar to Python's built-in `input()`, [with some caveats](../../concepts/human_in_the_loop/#interrupt). We demonstrate an example below.\n",
    "\n",
    "First, start with our existing code from Part 3. We make two changes, highlighted below:\n",
    "1. We add a `human_review_node` to handle the interaction with a human reviewer;\n",
    "2. We use a different condition in our conditional edge that routes to the `human_review_node`, instead of directly to tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a81608a-373a-4339-b1c6-65b73a92b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "# highlight-next-line\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# We add a node to handle the interaction with a human reviewer\n",
    "def human_review_node(state: State) -> Command[Literal[\"chatbot\", \"tools\"]]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    tool_call = last_message.tool_calls[-1]\n",
    "\n",
    "    # this is the value we'll be providing via Command(resume=<human_review>)\n",
    "    human_review = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            # Surface tool calls for review\n",
    "            \"tool_call\": tool_call,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    review_action = human_review[\"action\"]\n",
    "    review_data = human_review.get(\"data\")\n",
    "\n",
    "    # if approved, call the tool\n",
    "    if review_action == \"continue\":\n",
    "        return Command(goto=\"tools\")\n",
    "\n",
    "    elif review_action == \"feedback\":\n",
    "        # NOTE: we're adding feedback message as a ToolMessage\n",
    "        # to preserve the correct order in the message history\n",
    "        # (AI messages with tool calls need to be followed by tool call messages)\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            # This is our natural language feedback\n",
    "            \"content\": review_data,\n",
    "            \"name\": tool_call[\"name\"],\n",
    "            \"tool_call_id\": tool_call[\"id\"],\n",
    "        }\n",
    "        return Command(goto=\"chatbot\", update={\"messages\": [tool_message]})\n",
    "\n",
    "\n",
    "# Where we used tools_condition before, here we update the condition\n",
    "# to route to the human review node first, instead of tools.\n",
    "def route_after_llm(state) -> Literal[END, \"human_review_node\"]:\n",
    "    if len(state[\"messages\"][-1].tool_calls) == 0:\n",
    "        return END\n",
    "    else:\n",
    "        return \"human_review_node\"\n",
    "\n",
    "\n",
    "graph_builder.add_node(chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "# highlight-next-line\n",
    "graph_builder.add_node(human_review_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    # highlight-next-line\n",
    "    route_after_llm,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813505b2-18c1-46e9-b891-20a34232808b",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "!!! tip\n",
    "\n",
    "    Check out [this guide](../../how-tos/human_in_the_loop/review-tool-calls/) for more detail on human review of tool calls, including how to edit tool calls directly.\n",
    "\n",
    "---------\n",
    "\n",
    "We compile the graph with a checkpointer, as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0883e32-1a39-4ce9-ae32-bbd66708fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e84db-925c-4468-b3e0-639e6b25ac3c",
   "metadata": {},
   "source": [
    "Visualizing the graph, we can see that we've added a new node to mediate the interaction between the chatbot and the tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b8e61b5-f3c2-4917-a8fc-928ccbcfc6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAFcCAIAAABumWMEAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcU9f7B/CTBQkZrLCnijgQAQXrFreiILhrwT2oq1ZRa9VWq3Vrra3WrS3YKg5AcFXEBYoDRMXBEhRFZkgCAbJ/f1y/1J+SACHJTcLz/sOX5K4HCJ+ce++55xDkcjkCAIDmI+JdAABAX0F8AABUBPEBAFARxAcAQEUQHwAAFUF8AABURMa7AABahF8h4VWIBXxJDV8iEepHNwSKEYFIJtBZZDqLxHagGlEJeFekIgL0+wD6qKxQlPe0Kj9TwDQnSyRyOotMZ5GNqAS9eDsbGRP5HEkNXyLgS6oqJUwLStsudPfuTBMmCe/SmgfiA+gZbpn4Tnw5xZhoZkVp68mwtDPCu6KWepdbm58pKC8Ssh2MeweyifpzRQHiA+iT1IucnEdVfQLZbbvS8a5F/TJucFPiywdOsO7ck4V3LU0C8QH0RvQvhd4DzN27MfAuRLNSL3LqaqT+463wLqRxEB9AD8jlaP/KvLELHW2cjfGuRRuepvCKC+qGfmWDdyGNgPgAemBfRN6sDW2MafpzVaDFnt3h52RUBc93wLsQZSA+gK6L3lXoP97aunW0Oz6WcYNbzZX0DWbjXYhCrSjOgT66m1DhM9C8FWYHQsjb34xMIWanV+NdiEIQH0B3cYpF+c8E7X0M/FqpEj6DzG6cLsW7CoUgPoDuSokv7x2ou013LTCmET37mKYlVuJdSMMgPoCOKs6vM2GSXTubaOdwmZmZQqEQr82V6DXa8k1WDdLJS5QQH0BH5T6utrTVUo/S+Pj46dOn19bW4rJ5o4xpxFdPBRraeUtAfAAd9Sqzuq2nlrqWqtxwwG5caqjdUa9NF/qrTF28gArxAXRRRZHI0taYZUlR+55fv34dHh7et2/fgICATZs2yWSy+Pj4LVu2IISGDBni6+sbHx+PEMrIyFi4cGHfvn379u07b968Fy9eYJtzuVxfX9/IyMg1a9b07dt3zpw5DW6uXu08Gbwysdp323LwwD7QRdxyMUEzT59u2LChoKBg2bJlAoHg4cOHRCKxT58+oaGhUVFRu3fvZjAYzs7OCKGioiKhUDh79mwikXj69OnFixfHx8dTqVRsJ0eOHJkwYcL+/ftJJJKNjc3nm6uXEY3IKRXV1cioJrr1eQ/xAXSRgCehszTy5iwqKurYsWNISAhCKDQ0FCFkYWHh6OiIEOrSpYuZmRm22siRIwMCArD/d+7cOTw8PCMjo2fPntgrnp6eCxYsqN/n55urHZ1FFvAkVBPderwY4gPoIgFfU/EREBBw/Pjxbdu2zZ4928LCQtFqBALh+vXrUVFR+fn5JiYmCKGKior6pT169NBEbUrQWaQavkTXRifQrbYQAB8QENlII2/OBQsWLF269N9//w0KCoqOjla02uHDh5cvX965c+ddu3YtWbIEISSTyeqX0mg0TdSmhBGN9NHxdQXEB9BFNDqpiqORi4UEAmHKlClxcXEDBgzYtm1bRkZG/aL657+EQuGxY8eCg4OXLVvm7e3t6enZlD1r9PExXpmIztK5scggPoAuorPINXyJJvaM3WSl0+nh4eEIoZcvX9a3JsrKyrB1amtrhUJhp06dsC+5XO4nrY9PfLK5Jgj4UhPNnM21hM4VBABCiGlB0dDJy8qVKxkMRs+ePZOTkxFCWEZ4eXmRSKQdO3YEBQUJhcJx48a5ubmdPHnS0tKyurr64MGDRCIxNzdX0T4/31y9NctlyMLWSAdHQoXWB9BFti7G+c+q6wRSte+5S5cumZmZmzZtevny5erVq728vLBbJ6tXr379+vWOHTuuXr2KENq0aRONRlu1alVkZOS33347a9as+Ph4sbjh86nPN1evV0+rde2WLQbG+wA6Kulkqa0rVV9G/dSoxL9LHN1MOvZg4l3Ip+DkBeiodl0Zr18oe9CDw+GMHTv289flcrlcLic2NGD5N998g/X40KjZs2c3eKbTqVOn+t6rH+vVq9fmzZuV7LCGL3X10MWhoaH1AXTXqZ2FAydaWzs1PFaQVCotKSn5/HWZTCaTycjkBj4aTU1N6XSN/x2WlZU1eJpDIDT850alUpX0QHl8k8vnSPqF6OLABRAfQHe9za59mMjR8fE+NW1fRN68LW1JZF2ciU4Xr8cAgHF0p5laUory6vAuBDdPbvF6B7J1MzsgPoCuGzjJ+sKRImGN7vW41Lz8Z4I32TXeA0zxLkQhiA+g675c4fz3ttd4V6FtlcXiW2fLRs+2w7sQZeDaB9ADwlr5P9tfh37nQjbS0Wa8ehW9qrt1tnRShDNBt79diA+gH/gV4r+3vhm7yMnaSbeeOlW7l/ernt3jjVvkiHchjYP4APok8USJSCjrHcg2s1L/QGS4e5NVc+d8uUsneq/RlnjX0iQQH0DPvHoiSIkvb+/NtHY2btuFjnS7ed8UdQLZq8zq96/qqnmSPoGWbAe9mRML4gPopZxH1TnpVa8yBZ59TIkkggmTZMIiGVGJevF2JlMIAp5UwJfUVEl55eKywro2noyO3VkO7al4l9Y8EB9Av71+UcMtFdVUSQV8iUSs5rezUCh8/vy5j4+POneKEI1BksvkJkyyCYtkZU+1baM3zY1PQHwAoND79+/nzJmTkJCAdyE6Cvp9AABUBPEBAFARxAcAChEIhHbt2uFdhe6C+ABAIblcnpeXh3cVugviAwBlWCwY7kwhiA8AlOHz+XiXoLsgPgBQiEAg2Nra4l2F7oL4AEAhuVxeXFyMdxW6C+IDAGXc3d3xLkF3QXwAoEx2djbeJeguiA8AgIogPgBQxtzcHO8SdBfEBwDKVFZW4l2C7oL4AEAZS0v9GPgLFxAfAChTUVGBdwm6C+IDAKAiiA8AlGnTpg3eJeguiA8AlMnPz8e7BN0F8QEAUBHEBwDKQKd1JSA+AFAGOq0rAfEBAFARxAcAChEIhA4dOuBdhe6C+ABAIblcnpWVhXcVugviAwCgIogPABSCiRqUg/gAQCGYqEE5iA8AgIogPgBQBuZ5UQLiAwBlYJ4XJSA+AFAGnrhVAuIDAGXgiVslID4AACqC+ABAGWtra7xL0F0QHwAoU1paincJugviAwBlYLwPJSA+AFAGxvtQAuIDAGWg9aEExAcAykDrQwmIDwCUsbe3x7sE3UWQy+V41wCAbgkNDeXxeEQiUSKRVFZWstlsAoEgEokuXbqEd2m6BVofAHxq4sSJHA7n3bt3JSUlIpGoqKjo3bt3RCL8sXwKfiIAfCooKMjZ2fnjV+Ryeffu3fGrSEdBfADQgClTphgbG9d/aWNjM23aNFwr0kUQHwA0IDAw0NHREfu/XC7v0aMHjFr4OYgPABo2depUOp2ONT3CwsLwLkcXQXwA0LBRo0Y5OTlB00MJMt4FANBUtdXSsndCUZ1Ma0cMGjyXVHdhaO+w3MfVWjsonUVm2xtTjAlaO6LKoN8H0AMSsfxqVMm7vFqnDnSRUHvxgQuhQMrniN28GP3HsvGupREQH0DXCWtlZ/e8/WKktbULFe9atOdZKreyqG7kDFu8C1EG4gPouj9/Khg2zZFh1upOtLMf8jnFtUO/ssG7EIXg0inQaU9v89x8TFthdiCE3H1Zwlp56Rsh3oUoBPEBdFpJYZ0Ji4R3FbihGBHL30N8AKASkVDOtKDgXQVuzKyNBDwJ3lUoBPEBdFqdQCo38DstyohFMqnupgfEBwBAVRAfAAAVQXwAAFQE8QEAUBHEBwBARRAfAAAVQXwAAFQE8QEAUBHEBwBARRAfAAAVQXwAAFQE8QFahZzcrIGDfe/evd2sraRS6dOnGR+/suaHZfPCQ5t79M/3YxggPgBQaPvODbt2b9Kd/egaiA8AFBIJ1TPWhrr2o2ta4yBOwLDV1dVFRh2+fv3fsvJSGxu7YUNHfTVlBrYovyDvZPRfWVnPHR2dv1m00tPTGyFUWlpy5Ni+e/dSBIJqJyeXKV/OGDJ4BEJoy7Z1129cRQgNHOyLEPr7xHk7W3uEkKBG8OO6FemP7hsZGQ8eNGLWzPnYfHQSieTY8f1X/k3g8bguLm2mT5vXt4//5/s5E33Z0lLXx0BuIogPYFCkUun3q5c8zcwYGzLZrZ17wetXhW9fk0gfxiuLOnFk4oSwkSOC/v7n+Oq1S/+OOs9gMCRSycuXz8YEjTdlmd1KTvp50xoHB6dOHT1Cp8wsKy15//7dqu9+QghZWnz4my8ped+rZ78F85c9eHD39JkT74oKf96wCyG0Y+fGxGuXQr+a6eraLvHapbU/RPz6y6GuXX0+2Y+pqRmuPyF1gvgABuXmrWuPMh4uj1gbMHLM50u/WbRy+PDRCCEX5zbzF05PS783oP9gezuH40dPEwgEhNDIkWNCxg1JSbnRqaOHo6OzqakZp7ICa6TUa9vGbcH8pQihEcMD2Wzr6NNRjx+nm5tbXPk3YWrY7OnT5iGEBvQfHDo15PifB3bt3K9oPwYA4gMYlPsP7hgbGw8fNrrBpSyWKfYfV9d2CKGyshLsy9y87ON/HsjKeo61XziciiYeLiR4UvTpqEcZD7Hzkb59B2KvEwgEP9+eVxMvquN70l1w6RQYlEpOBdvSqv5sRREikYglBUIo/dGD+QumiUWiFct/XP/jNhbLVNbk8RHZbCuEkEBQLRBUI4TMzSzqF7FYpjU1NQKBoGXfkE6D1gcwKAwGk1PZ1LYDJjLysL2946afd5PJZIQQjUr7eKnyiZC43EqEkLm5BZttjRDi83lYoCCEOJwKMplMpVKbsh89Ba0PYFB8fPxqa2uvJV2pf0UiaWSsYR6f69bOHcsOkUhUU1sjk31ofVCpNA6nov7Lz928mYgQ6tatR6dOXQgEQuq9ZOx1kUiUei/Zw6Mr1g5qdD96ClofwKAMHRIQGxe9ZeuPL18+c2vn/io/Ny393sH9J5Rs4u3te+VK/MVLcSym6emzJ6qq+AX5eXK5nEAgeHXtduny+V2/bPLs4s1ksnr37o8QynuVs3ffrnbt2mdlPY9PODeg/+COHTojhIYPG338zwNSqdTe3vHChRgOp+L7VRuwQ3y8HwcHpy5dvLT189AsiA9gUIyNjXfu2H/o0G9XEy8mXDhna2s/0H+Y8gbIzOlfcyrKf/t9O5PJGj1q7MTxobt2b3qU8bCbj9/QoQFZ2c//vXrhburtEcMDsfj4cvK0zMzHCRfO0emMCeO/mjE9HNvPkm++o9MZMbGnqqr4bVzbbdr4SzcfP2zRx/uZOeNrg4kPmOMW6LRzv7/z7Gdh60prwroG6PFNDpmMegZYNGFdHMC1DwCAiiA+AAAqgvgAAKgI4gMAoCKIDwCAiiA+gI7icrnLli17+7YQ70KAQhAfQIfIZLItW7bMnj0b67gZGBjo4OCId1FAIYgPgL+TJ0/Onj1bJBLJZLJ27dpt2LABIWRtbe3v7489Rw90E8QHwMedO3dWrVqVn5+PNTQWLFhgZGREJpMnTJhgZ2eHd3WgSaDTOtCevLy8uLi4fv36+fn55eTkDBw40MXFBSE0depUvEsDqoD4AJrF4XDOnz9va2s7YsSIe/fu2djYdO7cGSE0bdo0vEsDLQXxAdRPKpVevnxZJBKFhISkpKRUVVWNGDECITRlyhS8SwPqBPEB1CYtLe3u3bsLFy4sKiq6d+/e+PHjEUKBgYF41wU0BS6dghYpKCg4efIk9kR8ZGSkqakpQsjJyemnn37q2rVry/dvatmqP+HIRkQaXXf/SHW3MqCzhEJhUlJSZWWlVCqNiIh4+/YtNnTo7t27w8LC1HssGoNc/rZOvfvUI8X5NaZWRnhXoVCrjnbQLJmZmVQq1c3N7bvvviOTyT169CCRSGfOnNHoQV06mTy9w9foIXSXHIlqZU7uujvWCQwXBJSpqKiorq52cXHZsWPH06dP16xZ0759e80djs/ni0QioVCI/VtXV+ft7X3/CodbLu012kpzx9VN//5V5DfMzLmDCd6FKATxARrw+vVrFxeXv/76KyoqatOmTb6+vnV1dfWDhmtCUFAQkUiUSCRyuZxMJsvlcplMJpfLjY2Nz507l57ELXkjtG1jwnYwJpEMvB9qrUDKKxVl3KgYMd3Ovi01NTXV2NjYxMTExMSETqcbGxvT6XS8a/wA4gN8UF5ezmaz8/Lypk6dOm/evKlTp5aVlVlZaekzf/z48QUFBZ+8aG5uvmbNmgEDBiCE3ryozX7ErxXIKotF2inpc3K5TCCoYTAYGj0Kw5Rs5WTcbZA53ZSEEAoICKDRaNjfKZlMJpPJQqGQTCYzmczDhw9rtJJGQXy0dhKJhEgkTpkyhUajHTt2jMvlUqlUjTY0FOnZs+fHYxoTCISxY8euWrVK+5UoMXDgwLi4OBaLpbUj/vLLL//8888nkzzIZLL09HSt1aAIxEdrJJFIyGTy9u3b4+LiLl++TKfT8/Ly3Nzc8K1q1KhRJSUl9V+2adPm9OnTuFbUgEePHrm4uFhYaHXs4kmTJuXm5n789CCDwbhx44Y2a2gQ3LhtXRISEsLCwl69eoUQ6t27d2JiIoPBIBAIuGdHeHj4yJEjTUw+XCa0tLRcu3YtviU1yMfHR8vZgRBavXo1m82u/1Iul8fGxmq5hgZBfBi+zMzM9evXp6SkYHO7rlq1yt3dHSHUp08fXE5SPlZUVPT8+XOE0OLFixcuXHjr1i2EEIVCCQoKUkuvM7V78uTJqVOntHzQrl27jho1CpsHD2t6jBs37sCBA1ou43MQH4aJy+WePHkyNTUVe8f7+Pj06NEDuw6HPbGmCwoKClauXGljY4MQqq+KwWC4u7svWLAA7+oaZmlpeeKEsjnrNGTx4sXt2rXDLgndvHnz2rVrBAJh0KBBiYmJ2i+mHlz7MCgZGRkIIW9v7/3791dXV0+bNk1rt06a5fDhwyEhIVKp1NraGu9amo3H47FYLO2PY5SRkbFy5UoqlRoXF1dfyaFDh54+fbp8+fIuXbpouR6ID0Mgl8tzcnLc3d2joqKuX7++bNky3WlfNGjlypWurq5ff/013oUYiMzMzO3bt3fo0GHlypXYjNzaIwf6qbq6Wi6XZ2RkdO/e/cyZM3K5vK6uDu+ilElOTr5//75cLhcIBHjX0iInTpyIjY3Fu4pPXbhwwc/PD3snaA1c+9A/VVVVs2fP/v777xFCDg4ODx8+HDduHDY7NN6lKfTo0aNTp055eHgghOpvr+gpCwuL+/fv413FpwICAu7fv5+VlbV27dp3795p56Bw8qI3jh49euPGjb/++ovL5RYUFHh7e+NdUeMEAsGuXbvWrl3L4XC0f79TQ+RyuVAoxP2mlSIvX75csWJFcHDwzJkzNX0saH3otNzc3D179pSXl2OX3H/44QeEkJmZmV5kB0Jo1apVPj4+2Cc23rWoDYFA0NnsQAh17Njx/PnztbW1kydPLioq0uixoPWhix4/fmxubu7s7Iw94RoaGqrtS2ItExMTI5FIJkyYgHchmjJjxozVq1fj3tdOudzc3IiIiKlTp44dO1ZDh4DWhw4pLi7GBt359ddfjYyMEEIbN26cNm2afmVHQkLCs2fPQkJC8C5EgxwcHHJycvCuohFubm6xsbEvXrz47rvvNHUMbV6nBYpkZ2ePHDny9OnTcrm8qqoK73JUUVhYuG7dOrlczuPx8K5F48RisUgkwruKprp69WpoaGhhYaHa9wwnL7ipq6s7fvw4l8v97rvv3rx5Y2xsjPW/1DvYA3hLliyZNm0adqXD4AmFwtraWjMzM7wLaSqBQPDVV18tWbLE399fjbuFkxdt4/F4CQkJ2JxJZDIZm8/V2dlZT7Pj2LFj58+fx865Wkl2IITev38/a9YsvKtoBjqdHhsbGx8ff+TIETXuFuJDe6qqqhBCISEh2DUODw+P2bNnf/wkpd5JTk4WCASauzKns1xdXXW5l40iO3fuFAqFu3btUtcO4eRFG2JjY7du3RoTE2Nra4t3LWqQlZV14MCBXbt2CYVCffwrauVu3Lhx/vx5tYQItD40RSKRnDx5Mjk5GSFkZ2d38+ZNA8gOsViMENq7d+/cuXN1vJ+rphUUFGDNSb3j7+8/ZsyYxYsXt3xX0PpQv7dv3zo6Ov7++++1tbXh4eFMJhPvitTjwIEDrq6uw4cPx7sQnbB169Y2bdpMnDgR70JUlJKSEhUV9ccff7RkJ6R169apr6TWrrq6etasWXK5HBtfo0+fPgbz+ZyYmMjlcidNmoR3IbqCy+VWV1d7eXnhXYiKnJ2dsaFDunfvrvJOoPWhBmKx+M8//5wwYYJYLC4tLdXx5+WbJS8vb8+ePb/++it2dxbvcoCanThxorCwUOV+ZXDto0WwkcEnTZokFotZLBabzTaY7MAucxw+fBgbmAOy4xMSiYTH4+FdRUt99dVXBAIhOjpatc2h9aEikUi0e/fugQMH+vn54V2L+h09etTc3NywO563UElJyYwZMy5evIh3IWoQHh4+e/ZsX1/f5m4IrQ8VXbx40cXFxSCzIzU1tba2FrJDOTabXVdnIHN379+/HxsIorkbQuujeWJjY/fv33/58mW8C1G/kpKSHTt2bN++XSQSYQ/sgdYjNTU1MjJy7969zdoKWh9NhZ3ovnr1Cutybni2bNmC3ViB7GiFevbsaWVlFR8f36ytoPXRJL/99lv37t179+6NdyHql5CQUFVV9eWXX+JdiP5ZvHjxjBkzDOlJn169et28ebPpnx/Q+miEVCp9+/Ytk8k0vOyQy+XPnj17+PCh/vZ9wheNRquoqMC7CnXCzl6bvj60PpS5c+eOu7u7mZmZ4d223Lx5c0REhFAo1PR88QasurqaTCbr8sCFKggNDV2zZk3Hjh2bsjK0PhQqKCj4559/2Gy24WXH999/3759ewqFAtnREgwGw8CyAxuH8ejRo01cGVofCr148aJTp054V6FOz58/T09PDw0NxbsQAxEdHS0SiQzv5xkSEvLrr786Ozs3uia0PhqQlpYWHx9vYNnx/v37zZs3Dxs2DO9CDIdUKsWGbjEwM2bMOHbsWFPWhNbHp3Jycvbv379z5068C1Gb2NhYbIg6PRpcTy8IBAKRSGRubo53Ieq3ZMmStWvXWlpaKl8NWh+fat++vSFlBzaFspmZGWSH2tHpdIPMDmyEmmvXrjW6GsTH//Py5UvdH4C/ibDnoEaNGrV27Vq8azFMDx482LBhA95VaMTgwYMhPpotIiLCMG5G9OvXz9raGiFkb2+Pdy0GSyaTvX//Hu8qNMLX1zc3N7fRp2Dg2sd/iouL09LSRo0ahXchqnvz5o1MJnN1dYXnVrRAJpOJRCLDu3eL2bRpU4cOHbDZ1xWB1sd/bG1t9To7UlJSvvnmG6zRAdmhBUQi0VCzAyE0fPjwFy9eKF8H4uM/mZmZDx8+xLsKVTx69AgbuDgmJsbExATvclqL7OxsbJoeg+Th4XHp0iXl60B8/Ofdu3fnzp3Du4pm27lz5+3bt7HzVbxraV0IBEJ1dTXeVWgKlUp1dnbOzs5Wsg5c+/hPSUnJlClTqFQql8sVi8X379/Hu6JGZGdnu7u7p6WltWS0W6AybLzCRjtH6K/Nmze3b99+/PjxilaA1gcKCwvr2bNn9+7dR40axePxSkpKhEKhlZVVbm4u3qUpVFpaGhwcjI20CtmBFzKZbMDZgRDy9PR8+vSpkhUgPlBkZKSDgwOBQKh/RS6X0+l0Nzc3XOtS5smTJ7/99pvBDMusp969ezd58mS8q9AgiI8mmTVr1sfdBwkEQrdu3XCtqGFPnjzBZmkaMmSIk5MT3uUAVFNTg3cJGuTi4sLhcIRCoaIVID4QQiggIGD48OH1N+GYTGbPnj3xLur/KSkpQQgVFRVduXIF71rABzY2NgcOHMC7Cs2ytbUtLCxUtBTi44OIiAgvLy+ZTIaN49C+fXu8K/rPvn379u/fjxAaMWIE3rWA/5DJZDs7O7yr0CwnJ6c3b94oWgrx8Z+NGzdi1zvs7e0dHBzwLgchhMrLyxFCLBbrxx9/xLsW8KmysjJsqnAD5uzsrCQ+mjCOlhyJRfKaKoma69I9RMRYFL5y165dft4DeOVifIuRSCQ7duwYM2YMpZNp4IhJeNVjyqbgcly9IJFIDGaqF0WcnJwyMzMVLW2k38fze/zHt3i8chGNbmgD9uk4mUyKEIFIxLN5aGFr/Carul1XZu/RlixLeAN8MHfu3LS0NOwSu0wmIxKJ2B8R9qKBefz48dmzZ3/66acGlyp7T6QlckvfCv0n2jHM4K3TSsmkiFcuOrvnbfB8R3MbeBsghNCCBQtWrFiBjbGO5TuBQNCRs121MzU1ffbsmaKlCj/c7l3mcErFfUNsIDtaMyIJmdsYjV/qGrvvLZ9j+CewTeHl5eXp6flxs51EIgUGBuJalKaYm5tXVlYqWtpwfFSWisvfiXqOstJkYUCfDJxsl3rBoOY0aYmwsLCPB1JxcXEx1Hm2TE1Nq6qqsDuSn2s4PsqLhPAoDPiYmZVR3hODfTysuby8vLp06YL9n0gkBgYG0ul0vIvSFCUNkIbjo6pSYuVosAMZABWQKARHdxM+B+cbUrrjyy+/tLW1xZoeSh4qMwDNjg+JUCaqa7i5AlqtivdChAhNWLFV6Nq1a9euXSkUSmBgII1Gw7scDfL09OTz+Q0ugsuioFUQi+Rvc2p4ZZKqSolEjGqq1dCM8rabxfjC31zU5cJRNcz2YmRMMmGRWOZkc2uKo7sO5VFFRYWiYU0gPoCBe3Kbl5VeVfZWaO7AksvkFGMSxYSilne+EZ3WuStbipBUHXWKauSVHElBVi2RVMs58M6lE6ODL7O9N/6XVGg0Wm1tbYOLID6Awcq4wU2JL7dxMzNhm3d216drebbulvyymsx7tXfiy/uNYbftimeIUKlURZ1rIT6AAaooEl2JKiXTjDsPbkPQw8s1BCLB1IaOEN3EkpH6L+dlWnXADBu8ilHS+oBH5oBa1+MNAAAfb0lEQVShefmg6vyhYpuONtZuFvqYHR8zplPsPWwIJqy9y3IrS/G57UWj0RS1PiA+gEHJfVKbdqO6TQ8HEsVw3ts0llHnQa5nfyuq5uJwP5TNZpNIpAYXGc6PGICnKfzUS1yHLtZ4F6J+BCLBrbfjyZ1vuGXaboPU1dXxeLwGF0F8AANR/Fr48BrXsasBZke9dj0dT2x5reWDkkgkbFDuz0F8AEMgl6Hrp8vb+BnmY6/1CERCWz+Hi8dKtHlQEokklTZ8bxriAxiC5PPlRkwd6mqlOTRTI26F9NVTgdaOCPEBDFmdQPr8Ht/S2RTvQrTE0tXidmy51g6njfgIHOP/x/7d6tqbjnv1KjdozMDklBt4F9KIjZvWTJ2ubIZ0w5B+nWvrrqPTNf20bfSZuC3q3acxncJg03MztNQAodFoip4nhtaHKshkMoPBJJOg051OeJ7Kp5u3ijOXemSqUVZ6lXaOJRaLFd15ae1/AHK5nND8rkXOzq5/nzivmYpA85QWCilUMtm44Y4JhoppZfLyRpl2jkUgKBwRWZ3xUV1d9fPmtSkpN0xZZpMnTxsTNB4h9DDt3vIVC/b+dqxzZ09stZGj+oYET5o7Z9GZs3/fup00bOioP/86yONx27VznzVzfmLipZSUG2QKZdjQUXPnLCKRSCKR6K/IQ0lJV0rLSiwt2cOGjpo+bR7Wj2XND8ucHF3IZHLChRiJWNyzZ99vFn/HYDCUFPnrnq03b12LWLpm3/5f3r0r3LF9X/duPd4XF+3btyst/Z6RkbF7+44zZ87v2KHzyVN/HTi456/jZ52cXLBtv106r7a2Jjh44tZt6xFC27ft9e3+BXZj/PCRvdeSLotEQidHl4kTwwYNHPb8ReaChdO/X7Vh6JCR2Drfr16ya+d+bFdJ1//dsPH7E1Fx9nYN3yzIyc1atHjmlk17Dh7+LS8v28bGbt6cxX36DMCWPn+Ruf/A7qys51QqrXev/l9//S2Lyarf859/HSwpee/q0vaTQaLizp+JPh1VXl5qa2s/eNCISRPDjI2NW/xrx9m7nFqWjbLfeEvkvkq7eHVfUXE2k2Hh1sZ35NCvWUw2QmjNz4PHBa7MfHHjeVYKjcro6RcybOBsbBOpVJp440jqw1iRqLZd2+5isUaGYieSCNauzHe5dQ5ueD7Lo86Tl0uXz5NJ5G+XfO/apt3uX7c8efKo0U2ePs1ISrqy7oet361c/+ZN/vIVC4yMjHbs+CN4zMTo01GXr8RjV27S0u716t3/6/Bvu/n0iDpx9Oy5f+r3EH06qri4aNPPuxcuiLhxMzHqxJFGDyoQVB85tm/JN99t+GlHNx+/ioryRYtn8qt4CxdEzJu7WCwWf7Nkdn5+3ojhgWQyOfHaJWyrkpLijMdpgYHjfLz95s5ZVL83mUy2es23d+/e+mrKjG+XfO/m1mHDxu8vXorr3KmLjY1tyv+uj9y+nfQo4+HLrOfYlzdvJnZw76QoOzBCoXD9hu/Gj5uye9dBWxu7jZtW83hchFBBwatlEeFisXjF8h+nhc1JTr6+fv1KbJPEa5c3bPze0oK9aOFyP79eea9y6vd2/M+DBw/tGTRw2PKIH/wHDDkV/dfOX35u9Gel+4oLhQTNjEefk/fg0F+LbazbTAxe3b/3lFcFj/YfWyASfYiDk+fW29u6z5+1v5vXyH+TDj3PSsFej0nYfvXGkY7uvUNGRxhRqLV1mjrFEAnlvAqRhnb+MS21PoYNHbVyxY8IoX59B06cNPLGzatdu/o0utUPazebmZl7eHS9/+BOamryt0tWEQiEDu6d/v03IT39/qiAYBKJtG/vn/WnGEXv3966nTRxQij2paOj8/erNhAIhE4dPW4lJz14eDd83jfKjygSiSKWrunU6cNgc5FRh83NLHZu/4NMJiOEhg4JCJ0anHAxZtGCiL59/BMTL82YHo4QSrx2icFgDB40gkqlenX9bwbcW7eTnjx99M+JeDbbCiE0ZPCI2tqas+f+CRg5ZkD/IfEJZ0UikZGR0aXL5xFCCQnnOnboXFtbe//Bnalhcxr94SxauHzQwGEIodmzF84LD338JL1/v0FRJ44QicRtW39nMpgIISaTtWnLD48fp3fs6PH73h1du/ps37YXa529e1eYm5eNECovLzvx99E1q38e0H8wtmdLS6tfdm9euCCivtmipwQ8CdVCI2cusRd29vQNCRkdgX3p7vbF9j2TsnJTPTv7I4R6dAsaPGA6Qsje1v1+Wlx2bmrnDn3eFr1MfRgzeMCMkUPCEUK+PqPy8tM1URtCiEQhCXhqGSqgEVqKD1NTM+w/VCrV3t6xtKxJnVuMjD60n40oRhQKpT4m2FbW2IctQqiykvNX5KEHD1OrqvgIIezP5sOxjKn1m9jY2GVmPm70iFQqtT47EEL37qWUlpUEjO5X/4pYLC4rLUEIjR49NmL5/MzMx126eP179cLQoaPq58Gtl5qaLJFIpoQG1b8ilUrpdAZCyH/AkOjTUenp951d2jzKeBgUOO5q4sX5Xy+9dz+lrq5uwIAhjZZKo9LqvzUsBRBCGY/TfHz86n8Ifn69EEJZ2c/FEjGPxx0/bkr9EwrE//0nLe2eRCL5edOanzetwV7B3hDlZaX6Hh/CGhnTXv2X8DiV70vK8ss5hakPYz9+ncv78K42MvrwqyGRSKYsax6/DCH09PkNhFD/3v8Nm0wgaOruBIVKFvC0MfY9gUDAPlk/p6lLp0TF94qbqD7zOJyKueFf0WgmM2d8bW/vePTovsK3DffbpZApMlnjB6XRTD7+klNZ0atXv7mzF338Ivb3383Hz8HBKfHaJTKF8uZNwfoft32+t8rKCktL9q4d+z9+kUQmI4Q6Yecvd26+eJnp7Oy6cEHErdtJSdevPHyY2uiZy+ff2v/mjkICQbWZqXn9IiaThSULg8FECNna2n++eQWnHCG06efd1lb/77lve3vHptegm2QyuVym/nG9q6orEEJDB87u2nngx68zmezPVyYSydivhsstplIZdBNt9ECRy+VypI0BzeVyuaJO6xq/86LCfY1PnI8/W1nJ2fvbcRsbW4SQtbWtovhQDZPJ4vG4zs6uny8iEAijAoJPnvpLLpd37erj6tq2wc253EobG7sGL0P27zf4WtJlMpk8cUIYhUIJGDkmJvZUUdHbppy5KMJmW/P5/91Iq6zkIIQYDCaWKVxuA6PaMv/XxGjw29RrdBZZIpQiZhNWbQ4alYkQEouF1lbN+InR6eZ1ddViiYhCNlJzQZ+RCCVMc5zvnGq834e5mQVCqLziw02miopysbh5jwzy+VwzM3MsOxBCPD5X+cSazdWtW4/MzMdZ2S/qX/l4cJSRI4JqagTxCeeCAhseTbtbtx5SqfR8/JkGN/cfMITDqeDzecOHjcbOhvLz85p45qKIh0fXjMdp9UMw3Lp1DSHk6endrp07kUisv9b7MR8fPwKBEBN7qsEi9RrdlCQWqv8SgBXb2czU9kF6vFD04QcllUokkkbeuo4OHRFCj55cUXs9n5NJpAwWzvGh8cM7O7va2NhGRR0xN7Ooqa05cmSvoilnFPH29o2JjT567A8PD6/bt5Pu3UuRyWQ8Hrf+UksLTZs6NzU1efmKBRMnhJqbW9y/f0cqk278aSe21MzMvG8f/0cZD/v3G9Tg5kOHBMQnnNt/4Nf3xUXu7Tvm5mYnp1w/fvQMdpWkU6cu1tY2vt17YreT7Wzte/Toza3kNOvM5ROhU2YmJV1ZuWpR4OhxpaXFf/510Mfb19urO4FAGDki6MLFWJFQ2KNH74qK8nv3ks3NLRFCjg5OY0Mmnz33z/drvu3bx7+iojw2Lnrzpl/d23dUuQwdYetMzX2p/vggEAhjAr7985+Vvx2Y1avHWJlM+vDRxe7eIz6+rvE5L48hiTeOno3bUlzyysHOvaDwKb9KU70zyCRkZqXxNg6GQml4pnSNtz7IZPK6H7eRyOTlKxccPLRnatic5vY16N9v0NSw2bFxp3/+ebVYIt77+3FnZ9ePP0hbyMHe8fc9Rz08up74++jefTu5vMohg0d+vMLo0WMDRo5R9BOkUCjbt+4dPSokKenKrl82pT+6HxQ4vv5SE4FA6N9vcGDgfz3HxwSOb0nTA7vZtG3L72KxeNv29aeiI4cOCfhp/Q7sJHHRwuUhwRPT0u/v+2PXs+dP2rVzr99qwfylX4cvyX+V+8vuzRcuxvTrO9CKbQjPtju60/jFGpm/yrOz/8zQXSQS5fzFXxJvHDU3t23r2sidRBKJNDtst7vbF3cfnE248huRQKSbqOdD7hNSsYzzvsa2jTa67UilUkUf+Q3fkrl/mSOsQ94DLTRfG9AbZ38tGLvQkWWhcz2Vj60rcOhqZ0TTucI0h1tUTaPUDZ+qjQFQz5079+LFi9WrV3++yAB/4tXV1V9+NbrBRfPmfjN6VIjWK1Jo8ZLZ+fm5n7/eu/eAVSvX41GRXvLoZfruTZ2Ro8K+p5nPb56M+enz1ylkY7FE2OAmi+YctrFuo64KL17dd+f+2c9fp1GZivqVKS9AXCfy+kJTfW0/QSAQFD0yZ4DxYWJicvDA3w0uYjF165nuH9ZsFjd0Na6+uwdoiu6DzR6szDNXHB/t3XosnR/5+esSiZhMbvic1JSlzjO7AX2+6ukb/PnrcjlSdGdSSQG1fKG4uq5NFy3NYF9bW6uoE4YBxgeRSLRrqO+DDsI6qoIWIpEJ3YdYFL6qtGpr3uAKxkY0YyM8E5luYqrGziDlrzgDxzfQ/URDsG7TDS6CB/aBIeg50gKJRTKpNrpR4auWV2fnauzYXntpSCKRTE0bzj6ID2AgRky1fnXvLd5VaJa4Tlr0vHTIl1pttHI4HEWLID6AgWBakIdMtnqTXoR3IRqUd/dt6CoXLR+0trbWxMSkwUUQH8BwuHrQA2bYFma8x7sQ9RPVSl4kFcz5uY0xTdt/s8bGxnDyAloFtj1l8ETLrJuvhQJtPI2qHQJO3bsn72dvbEui4DDp5qtXr2CsU9Ba2LejTVvrKijmFL8sFddpY0QMzRFU1r1JL6JRamasc6UY4zNhL4/HU9T6MMAbtwBQ6cSxC+2y06puxxWxrE0oJsYsKzqRrDfzZYtrJfyyGrlELBOJhn1lZeuK54iEVlZWFhYNd0CH+AAGy7070707MzejOvuRIOtWuaUTXSyUk41IZKqRvJnPbWqBXCaXiiUSkdTIiFjFqWvrSW/vxXR0x78D4a1bt7Zv397gIogPYODcvBlu3gyEbIoLhNU8cQ1fKhbK6mp0rocIxZhgwqTSTcksc4qlvZYepW1UaWkpm80mKhhNFuIDtBa2rsYI6f3I8lpWVlb2xRdfKFracHwY0YhyvTlPBFpiaYfTtTuAn5ycHEUDnSq888I0p5S+NpDRqIBaiIWyotwapu49rQ80Ki8vr23bBsboxDQcHzZOxi0eohQYFG6pyM1b3QOKAp0nFArd3d0VLW04PhjmZCd32s0zxZosDOiTq1FFfYO195Qn0BFXrlzp2FHhiJYK26JeA8yojOrEqCKvARbmNsZkI2iNtEbVXAm/XHztn3cz1uHQXRrgKz8/38rKSsmsr8pOZTt0Z9DoxIybnKJXta02PGQyGYFAaPl0E/rI2onGqxC19WTM29KOpD99roC65OTkDBw4UMkKjVwJc+5o4tzRBCEkFurcfXLtWL169fBhw/v37493IbiQU4yhxdF6JSUlDRmibFjvpl5Ix6u/Pe76Dejl2taxtX77rfO7Bh8kJyf/+OOPSlaA+3CNCAwMxLsEAHDw+PHjYcOG0WjKes1D07QRKSkpb98a+BhWAHwuPj7e09NT+ToQH42Ii4vLysrCuwoAtO3SpUsjR45Uvg6cvDRiypQpNjbamIwHAN2RnJw8duxYbKJVJaD10Qhvb287Ozu8qwBAq44dOzZ48OBGV4P4aERmZubDhw/xrgIA7Xn27JlYLPb29m50TYiPRgiFwoMHD+JdBQDac+XKlZkzZzZlTYiPRvj4+EybNg3vKgDQkpcvX6anp/v7+zdlZYJc3kq7kwIAPjd//vxp06YpGSLoY9D6aNzDhw9///13vKsAQONSU1Pt7OyamB3Q+miqMWPG7N2719HREe9CANAgf3//+Ph4JrOpA7tAfDQJl8sVCoXQAQQYsK1bt7Zp02bixIlN3wROXprEzMyMTCZLJIYzcRkAH3vw4EFFRUWzsgPioxmEQmFISAjeVQCgfmKxeNGiRdu2bWvuhnDy0gyZmZmVlZX9+vXDuxAA1Gnu3LmLFy/u0qVLczeE+ACgVduwYYOnp2dwcLAK28LJS7NFRETcv38f7yoAUIODBw9aW1urlh3Q+lDRP//8M2jQILgRA/Ta3r17TU1NQ0NDVd4DxIfqHjx44Ofnh3cVAKji7Nmz+fn5ERERLdkJnLyo7vLly7dv38a7CgCaLTo6Oisrq4XZAa2Pljp37tzYsWPxrgKAZti+fbuxsfHixYtbvitofbQIlh1r1qypqqrCuxYAGjd9+nQnJye1ZAfEh3qEh4evXr0a7yoAUObFixe+vr4RERGTJ09W1z7h5EWd/v333yFDhhCJEMpAt5w5cyY2NjYyMlK98yXCG12d2rZtGxYWVl1djXchAPxn/fr1ubm5UVFRap9rFVof6ldeXi4QCAgEgrOzM961gFYtPz9///79ffr0CQoK0sT+IT40QiAQhIaGLlmyZMCAAXjXAlqpffv2JSUlbdu2rW3btho6BJy8aASdTo+JiWGxWNgITniXA1qXJ0+eBAUFGRsbnzlzRnPZAdNEaZaPjw92LjN69OiYmBgKhYJ3RcDwbdu27cWLF3/88YeDg4OmjwUnL9rw/v17FotVUVHx/v37pg8kCUCz3LlzZ82aNfPmzZs0aZJ2jgitD23A5qkjkUhbtmzJyclpyUNKAHyusrIyKioqOzs7JibG1NRUa8eF1oe2vXnzxtnZOTo6ul27dt27d8e7HKD3fv/999jY2FWrVjVlWkn1gkun2obdze3Vq9eBAwfy8/OlUineFQF9debMmV69etHp9MTERO1nB7Q+cFZdXU2hUObOnbt06VIvLy+8ywF64/bt2zt37uzZs+fSpUuNjIzwKgPiA3+ZmZkpKSnz5s3Lzc11c3PDuxyg07Kysn755Rcqlbps2TInJyd8i4H40CHJycnr168/ePBgmzZt8K4F6Jz8/Pzjx4/n5OQsXbrU19cX73IQxIfO4XA4paWlHTt2PHny5LBhwywsLPCuCOAvNzf30KFDeXl54eHhQ4YMwbuc/8CNW91iYWGBRQadTp80adKFCxeIRCKZDL+mVio7O/vQoUNv3ryZM2fO1q1b8S7nU9D60GkSiUQgEHz77bfz58/XkfYq0I6XL18eOnSoqKhozpw5gwYNwruchkF86IHHjx/fvXs3PDw8Pz/f1taWRqPhXRHQoKdPnx45cqSsrGzOnDn+/v54l6MMxIc+ycnJmTFjxrp163TqBBioy/Xr1yMjI0kk0tSpU/ViMkOID/3z7NkzDw+PU6dOmZqajhgxAu9ygBqcOXMmMjKyffv2YWFhetQDCOJDX71//37v3r3Dhg3r378/l8s1MzPDuyLQbDU1NZGRkZGRkaNGjQoLC3N0dMS7ouaB+NBvEomETCYvWrSITCZv374d7tHoi4KCgpMnT164cCEsLCwsLExPr2dBfBiIW7du+fn51dXVxcTETJ482cTEBO+KQMOuX79+6tSp8vLyKVOm6PskQRAfBkUmk/3xxx+FhYVbtmx59+6dFgaMAU1UXV0dHR0dHR3dpUuXSZMmGcb0phAfBishIeHQoUN79+7VuzNqA5OZmXnq1Klbt25NnDhx4sSJVlZWeFekNhAfhuzt27cSicTV1XXfvn1eXl59+vTR3LH4HMnDq5VFr2qkUlRXJdHcgVqOYW6EkNyxnUmPkeY0BklzB4qJiUlPTy8sLJw4cWJAQIDmDoQXiI9WIT09/fjx4z/88AOLxaqsrLSxsVHv/sveCi8ced9jhBXLksIwo+j6e4qIqjlifoX4bnzp+CWOZlZqHoP25cuXMTExZ8+eDQ4OnjBhQocOHdS7f90B8dGKyGQysVgcEhIyfPjwb775Rl27fZtTezumfPQ8nB8eV03s76+HT7W1djJWz95iY8+dOyeVSkNCQsaNG6f2aZl0DcRHa4R1PLt//35ycvLUqVPZbHZL9nZu77uBk+zJFL38U6kTyO6eLw4Kt2/JTl68eHHr1q3Dhw8HBQWNHTvWw8NDfQXqNOgm0Bph7+/u3bvn5OScOXMmPDw8LS3Nx8dHhdl5y9+J6qqlepodCCEqncgpFfErJCzLZv8t1NbWxsXFxcbGksnkyZMn37t3r7VNbwzx0XqRSKSvvvoK+39JSckXX3wRHx9va2vbrJ1wSkSO7emaKVBLnN0ZFe9FzYqP1NTUuLi427dvBwcHb9iwoX379posUHdBfACEEAoICAgICODz+QihL7/8Migo6Msvv2xwzeHDh1+5cqX+S4lIVluj36M911RLpBJZU9YsLi6Oi4tLTk5msVhjxozZvHmz5qvTaa2rrQWUw2bV3L59e01NDdax+vr165+sU1ZWFhYWhlOBuLly5cqCBQtmzZpFIBB27tyJPW2Ed1H4g/gAn3J0dJw1axZCyNLS8sKFCxs2bEAIcblchJC/vz+RSHzx4sWiRYvwLlMbsrOzt2/f3rdv35s3b4aFhV24cGHu3LnW1tZ416Ur4OQFKMRkMnfs2FFXV4cQunbtWkJCAp/Px64OPnjwYMWKFdu2bcO7Ro0QiURxcXFxcXFSqXTMmDGJiYlUKhXvonQR3LgFTTV8+PCKior6L42MjIKDg0f3Dy/MresdqMcfyDdPF3f0Zbh5M7BYjIuLu3bt2pgxY4KDgzt27Ih3dToNWh+gqXg83sdfikSiCxcumBI8XO30/ukvPp9/+PDJuLg4BweH4ODgjRs34l2RfoD4AE0lFouxbpRYixUbWyQtLc11tH7Hh1wm37NnT88hrgcOHLC3b1H/sdYGTl5Ak0yZMoVEItHpdDabbWVlxWaz2Wy2hYVFdZGZqMpUv09eoos7+n04eQHNAq0P0CR///13g68/T+UXVtVpvRy10tces/iDG7cAABVBfAAAVATxAQBQEcQHAEBFEB8AB89fZAqFwpbsgcfjDhzsG3f+jPqKAs0G8QG07fKV+AULp9fV1eJdCGgpiA+gbS1sdwDdAf0+gFbduJm4+9ctCKHgsUMQQitX/DhieCB2OrP/wO6srOdUKq13r/5ff/0ti8nCptE7dnz/lX8TeDyui0ub6dPm9e3TwKTzqanJBw//VlT01tbWPihw/NiQSXh8c60OtD6AVvl4+06cEIoQ2vzz7j27D3/Row9CqKDg1bKIcLFYvGL5j9PC5iQnX1+/fiW2/o6dG09FR44eFbL6+422tvZrf4h48uTRJ/usqalZ99NKI4rRsqVrevfqX1FRhsd31hpB6wNolampmb29I0KoU6cupqYfpvWOOnGESCRu2/o7k8FECDGZrE1bfnj8ON3c3OLKvwlTw2ZPnzYPITSg/+DQqSHH/zywa+f+j/dZyeUIhcJ+/QYNHTISp2+rlYL4APjLeJzm4+OHZQdCyM+vF0IoK/s5jWaCEOrbdyD2OoFA8PPteTXx4ieb29s5eHh0jTpxhEqlBY4ea2RkpPXvoJWCkxeAP4Gg2szUvP5LJpOFECovLxMIqhFC5mYW9YtYLNOamhqBQPDx5gQCYcumPcOHjd5/YPfU6WMfP07XbvmtF8QHwMfHj3qz2dZ8/n+DiVRWchBCDAaTzbZGCH28iMOpIJPJn4/9xWAwlnzz3Z/Hz9LpjDVrl2JjtQJNg/gA2kaj0rDGRf0rHh5dMx6nYaMiIoRu3bqGEPL09O7UqQuBQEi9l4y9LhKJUu8le3h0JZFIZDIFIVRVxccWYTeD7e0cxoZMrhZUFxcX4fGdtTpw7QNom0cXLxKJ9Pu+HSOHBwlFwqDAcaFTZiYlXVm5alHg6HGlpcV//nXQx9vX26s7gUAYPmz08T8PSKVSe3vHCxdiOJyK71dtQAjR6XQHe8fo01GmpmYjhgdOmzHOf8DQNq7t4uJOM+gM7Oos0DTSunXr8K4B6LGyt0I+R+LUoRkzRbGYLCsrmxs3rt69e7uqij98+GgWy9Szi8+Dh3fjE85mZb8Y6D9secQPxsbGCCE/314CQfWly3FJSVfoJvSIZWuwC6sIoU6dPV++fPbqVc6AAUPevn2TnHL9dnKSpaXVdyvWOTg0Iz5eP69m2xtZ2MIF12aD0cZAizxP5RvSUMmgWeDaBwBARRAfAAAVQXwAAFQE8QEAUBHEBwBARRAfAAAVQXwAAFQE8QEAUBHEBwBARRAfAAAVQXwAAFQE8QEAUBHEB2gRIolApen3u4hKJxGJBLyr0Ev6/YsHuGNZUkoL6/CuokVK39SyLCl4V6GXID5Ai1jaGpHI+v0uMqKSYLAP1ej3Lx7gztiE2M7T5E5cKd6FqOjm6RKPnkwiCe869BMMFwTU4FESt/iNsMdIKyOq3nwgiWplKedL2nVlePRk4l2LvoL4AOrxLJWfeYdfw5dY2BoLa6V4l6MMjUkqe1NnyqZ49jV17wbZoTqID6A2chkS8CV8jhjvQhpBIBBYFhQ6i4TgfkvLQHwAAFSkN2eqAABdA/EBAFARxAcAQEUQHwAAFUF8AABUBPEBAFDR/wEuRozPP7qmFAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f318020-ab7e-415b-a5e2-eddec6d9f3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_01UukDzyzhEhxMgTbshetpT4', 'input': {'query': 'LangGraph programming framework'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01UukDzyzhEhxMgTbshetpT4)\n",
      " Call ID: toolu_01UukDzyzhEhxMgTbshetpT4\n",
      "  Args:\n",
      "    query: LangGraph programming framework\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39405637-13b1-40b1-a51e-6d60bf675ff1",
   "metadata": {},
   "source": [
    "Let's inspect the graph state to confirm it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f511371-98b6-4513-b450-9143778f12dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human_review_node',)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89326046-2b11-4812-8b6d-8780306ec275",
   "metadata": {},
   "source": [
    "**Notice** that unlike last time, the \"next\" node is set to `human_review_node`. We've interrupted here! Let's check the tool invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3facda0a-e6ad-4b28-b627-753ad8c90c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'LangGraph programming framework'},\n",
       "  'id': 'toolu_01UukDzyzhEhxMgTbshetpT4',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "existing_message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55a4c70-7226-4be0-8562-391f72bc1f2b",
   "metadata": {},
   "source": [
    "This query seems reasonable. Nothing to filter here. The simplest thing the human can do is just let the graph continue executing. Let's do that below.\n",
    "\n",
    "To resume execution, we pass a [Command](../../concepts/human_in_the_loop/#the-command-primitive) object. Here, we specify `resume` with a dict containing the information expected by `human_review_node`. This information can be customized based on our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "831d4978-b5ea-4258-b350-8e7dd2bf2b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_01UukDzyzhEhxMgTbshetpT4', 'input': {'query': 'LangGraph programming framework'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01UukDzyzhEhxMgTbshetpT4)\n",
      " Call ID: toolu_01UukDzyzhEhxMgTbshetpT4\n",
      "  Args:\n",
      "    query: LangGraph programming framework\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"No. LangGraph is an orchestration framework for complex agentic systems and is more low-level and controllable than LangChain agents. LangChain provides a standard interface to interact with models and other components, useful for straight-forward chains and retrieval flows.\"}, {\"url\": \"https://academy.langchain.com/courses/intro-to-langgraph\", \"content\": \"Separate from the LangChain package, LangGraph helps developers add better precision and control into agentic workflows. Lesson 1: Motivation Lesson 2: Simple Graph Lesson 3: LangGraph Studio Lesson 4: Chain Lesson 5: Router Lesson 6: Agent Lesson 7: Agent with Memory Lesson 8: Deployment Lesson 1: State Schema Lesson 2: State Reducers Lesson 3: Multiple Schemas Lesson 1: Streaming Lesson 2: Breakpoints Lesson 3: Editing State and Human Feedback Lesson 4: Dynamic Breakpoints Lesson 1: Parallelization Lesson 2: Sub-graphs Lesson 3: Map-reduce Lesson 4: Research Assistant About this course No. LangGraph is an orchestration framework for complex agentic systems and is more low-level and controllable than LangChain agents. Deploy LangGraph agents at scale with LangGraph Cloud (available for Python).\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your patience. I've researched LangGraph for you, and I'm happy to share what I've found. LangGraph is an interesting framework in the field of language AI. Here's a summary of the key points:\n",
      "\n",
      "1. Purpose:\n",
      "   LangGraph is an orchestration framework designed for complex agentic systems. It provides more low-level control and precision compared to LangChain agents.\n",
      "\n",
      "2. Relationship to LangChain:\n",
      "   - LangGraph is separate from the LangChain package but complements it.\n",
      "   - While LangChain provides a standard interface for interacting with models and components (useful for straightforward chains and retrieval flows), LangGraph offers more fine-grained control for complex workflows.\n",
      "\n",
      "3. Key Features:\n",
      "   - Better precision and control in agentic workflows\n",
      "   - Allows for the creation of more complex and controllable AI systems\n",
      "\n",
      "4. Learning Resources:\n",
      "   There's a course available on the LangChain Academy that covers LangGraph in depth. The course structure includes:\n",
      "\n",
      "   - Motivation\n",
      "   - Simple Graph\n",
      "   - LangGraph Studio\n",
      "   - Chain\n",
      "   - Router\n",
      "   - Agent\n",
      "   - Agent with Memory\n",
      "   - Deployment\n",
      "   - State Schema\n",
      "   - State Reducers\n",
      "   - Multiple Schemas\n",
      "   - Streaming\n",
      "   - Breakpoints\n",
      "   - Editing State and Human Feedback\n",
      "   - Dynamic Breakpoints\n",
      "   - Parallelization\n",
      "   - Sub-graphs\n",
      "   - Map-reduce\n",
      "   - Research Assistant\n",
      "\n",
      "5. Deployment:\n",
      "   LangGraph agents can be deployed at scale using LangGraph Cloud (available for Python).\n",
      "\n",
      "LangGraph seems to be particularly useful when you need more control over your AI workflows, especially for complex, multi-step processes or when building sophisticated AI agents. If you're already familiar with LangChain, learning LangGraph could be a valuable next step to enhance your ability to create more advanced AI systems.\n",
      "\n",
      "Is there any specific aspect of LangGraph you'd like to know more about? Or do you have any questions about how it compares to other frameworks you might be familiar with?\n"
     ]
    }
   ],
   "source": [
    "human_command = Command(resume={\"action\": \"continue\"})\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d789d4cf-b498-454b-a088-3ffc03e511b0",
   "metadata": {},
   "source": [
    "Review this call's [LangSmith trace](https://smith.langchain.com/public/83aaec86-9dd8-406b-ab03-e66d2464b8ef/r) to see the exact work that was done in the above call. Notice that the state is loaded in the first step so that your chatbot can continue where it left off.\n",
    "\n",
    "Let's demonstrate another example, in which we direct the chatbot to revise its tool calls based on our feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ebad510-01f8-4b00-8e80-1b435b0f37fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Could you search the weather in San Francisco?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to search for the current weather in San Francisco for you. To get the most up-to-date and accurate information, I'll use the Tavily search engine. Let me do that for you right away.\", 'type': 'text'}, {'id': 'toolu_019rPs39MK72QMVFcnxEyFN4', 'input': {'query': 'current weather in San Francisco'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_019rPs39MK72QMVFcnxEyFN4)\n",
      " Call ID: toolu_019rPs39MK72QMVFcnxEyFN4\n",
      "  Args:\n",
      "    query: current weather in San Francisco\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Could you search the weather in San Francisco?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1e485c-0ddc-4c36-a1c1-b78f6c706fa1",
   "metadata": {},
   "source": [
    "This time, we will indicate that the requested action is `\"feedback\"`, and provide feedback in natural language. The chatbot will respond by generating a second, updated tool call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5bbaf35-d1f2-46b3-8451-856e908fd11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to search for the current weather in San Francisco for you. To get the most up-to-date and accurate information, I'll use the Tavily search engine. Let me do that for you right away.\", 'type': 'text'}, {'id': 'toolu_019rPs39MK72QMVFcnxEyFN4', 'input': {'query': 'current weather in San Francisco'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_019rPs39MK72QMVFcnxEyFN4)\n",
      " Call ID: toolu_019rPs39MK72QMVFcnxEyFN4\n",
      "  Args:\n",
      "    query: current weather in San Francisco\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "User requested changes: use <city, country> format for location.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': 'I apologize for the error in my previous attempt. Thank you for the clarification on the format. Let me search again using the correct format.', 'type': 'text'}, {'id': 'toolu_01AfrULohtNjWqGf8oY1FP9v', 'input': {'query': 'current weather in San Francisco, USA'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01AfrULohtNjWqGf8oY1FP9v)\n",
      " Call ID: toolu_01AfrULohtNjWqGf8oY1FP9v\n",
      "  Args:\n",
      "    query: current weather in San Francisco, USA\n"
     ]
    }
   ],
   "source": [
    "human_command = Command(\n",
    "    resume={\n",
    "        \"action\": \"feedback\",\n",
    "        \"data\": \"User requested changes: use <city, country> format for location.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56541f9-a5d2-49e0-9389-8d6e116c58b3",
   "metadata": {},
   "source": [
    "We can now continue, as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24ec8471-4438-4c89-aafa-48bb6c72eca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': 'I apologize for the error in my previous attempt. Thank you for the clarification on the format. Let me search again using the correct format.', 'type': 'text'}, {'id': 'toolu_01AfrULohtNjWqGf8oY1FP9v', 'input': {'query': 'current weather in San Francisco, USA'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01AfrULohtNjWqGf8oY1FP9v)\n",
      " Call ID: toolu_01AfrULohtNjWqGf8oY1FP9v\n",
      "  Args:\n",
      "    query: current weather in San Francisco, USA\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1736966001, 'localtime': '2025-01-15 10:33'}, 'current': {'last_updated_epoch': 1736965800, 'last_updated': '2025-01-15 10:30', 'temp_c': 10.6, 'temp_f': 51.1, 'is_day': 1, 'condition': {'text': 'Sunny', 'icon': '//cdn.weatherapi.com/weather/64x64/day/113.png', 'code': 1000}, 'wind_mph': 6.3, 'wind_kph': 10.1, 'wind_degree': 51, 'wind_dir': 'NE', 'pressure_mb': 1026.0, 'pressure_in': 30.3, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 46, 'cloud': 0, 'feelslike_c': 9.3, 'feelslike_f': 48.8, 'windchill_c': 6.6, 'windchill_f': 43.9, 'heatindex_c': 8.6, 'heatindex_f': 47.5, 'dewpoint_c': 4.6, 'dewpoint_f': 40.2, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 1.3, 'gust_mph': 9.4, 'gust_kph': 15.1}}\"}, {\"url\": \"https://www.meteoprog.com/weather/Sanfrancisco/month/january/\", \"content\": \"San Francisco (United States) weather in January 2025 ☀️ Accurate weather forecast for San Francisco in January ⛅ Detailed forecast By month Current temperature \\\"near me\\\" Weather news ⊳ Widget of weather ⊳ Water temperature | METEOPROG. ... 15 January +14 °+7° 16 January +14\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your patience. I've successfully searched for the current weather in San Francisco, USA. Based on the search results, I can provide you with the following information about the weather in San Francisco:\n",
      "\n",
      "1. Current Temperature:\n",
      "   - 10.6°C (51.1°F)\n",
      "   - Feels like: 9.3°C (48.8°F)\n",
      "\n",
      "2. Weather Condition: Sunny\n",
      "\n",
      "3. Wind:\n",
      "   - Speed: 10.1 km/h (6.3 mph)\n",
      "   - Direction: Northeast (NE)\n",
      "\n",
      "4. Humidity: 46%\n",
      "\n",
      "5. Precipitation: 0 mm (0 inches)\n",
      "\n",
      "6. Visibility: 16 km (9 miles)\n",
      "\n",
      "7. Pressure: 1026.0 mb (30.3 inches)\n",
      "\n",
      "8. UV Index: 1.3 (relatively low)\n",
      "\n",
      "The data shows that it's a pleasant, sunny day in San Francisco with comfortable temperatures. The weather is clear with no cloud cover, and there's a light breeze from the northeast. The humidity is moderate, and there's no precipitation expected.\n",
      "\n",
      "Is there any specific aspect of the weather you'd like more information about?\n"
     ]
    }
   ],
   "source": [
    "human_command = Command(resume={\"action\": \"continue\"})\n",
    "\n",
    "events = graph.stream(human_command, config,stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e78a97-474f-4709-b51d-9d5e8323e14c",
   "metadata": {},
   "source": [
    "In the [LangSmith trace](https://smith.langchain.com/public/1e4bf84c-3e9e-41fd-a924-21395f5cd09e/r) for the above run, we can see full sequence of alternating assistant and tool messages representing the interaction with a human reviewer.\n",
    "\n",
    "**Congrats!** You've used an `interrupt` to add human-in-the-loop execution to your chatbot, allowing for human oversight and intervention when needed. This opens up the potential UIs you can create with your AI systems. Since we have already added a **checkpointer**, the graph can be paused **indefinitely** and resumed at any time as if nothing had happened.\n",
    "\n",
    "Next, we'll explore how to further customize the bot's behavior using custom state updates.\n",
    "\n",
    "Below is a copy of the code you used in this section. The only difference between this and the previous parts is the addition of the `interrupt_before` argument.\n",
    "\n",
    "<details>\n",
    "<summary>Full Code</summary>\n",
    "    <pre>\n",
    "\n",
    "```python\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# We add a node to handle the interaction with a human reviewer\n",
    "def human_review_node(state: State) -> Command[Literal[\"chatbot\", \"tools\"]]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    tool_call = last_message.tool_calls[-1]\n",
    "\n",
    "    # this is the value we'll be providing via Command(resume=<human_review>)\n",
    "    human_review = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            # Surface tool calls for review\n",
    "            \"tool_call\": tool_call,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    review_action = human_review[\"action\"]\n",
    "    review_data = human_review.get(\"data\")\n",
    "\n",
    "    # if approved, call the tool\n",
    "    if review_action == \"continue\":\n",
    "        return Command(goto=\"tools\")\n",
    "\n",
    "    elif review_action == \"feedback\":\n",
    "        # NOTE: we're adding feedback message as a ToolMessage\n",
    "        # to preserve the correct order in the message history\n",
    "        # (AI messages with tool calls need to be followed by tool call messages)\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            # This is our natural language feedback\n",
    "            \"content\": review_data,\n",
    "            \"name\": tool_call[\"name\"],\n",
    "            \"tool_call_id\": tool_call[\"id\"],\n",
    "        }\n",
    "        return Command(goto=\"chatbot\", update={\"messages\": [tool_message]})\n",
    "\n",
    "\n",
    "# Where we used tools_condition before, here we update the condition\n",
    "# to route to the human review node first, instead of tools.\n",
    "def route_after_llm(state) -> Literal[END, \"human_review_node\"]:\n",
    "    if len(state[\"messages\"][-1].tool_calls) == 0:\n",
    "        return END\n",
    "    else:\n",
    "        return \"human_review_node\"\n",
    "\n",
    "\n",
    "graph_builder.add_node(chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_node(human_review_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_after_llm,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "```\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df38bc4-c177-4ccd-9ec2-83d32bf66722",
   "metadata": {},
   "source": [
    "## Part 5: Manually Updating the State\n",
    "\n",
    "In the previous section, we showed how to interrupt a graph so that a human could inspect its actions. This lets the human `read` the state, but if they want to change their agent's course, they'll need to have `write` access.\n",
    "\n",
    "Thankfully, LangGraph lets you **manually update state**! Updating the state lets you control the agent's trajectory by modifying its actions (even modifying the past!). This capability is particularly useful when you want to correct the agent's mistakes, explore alternative paths, or guide the agent towards a specific goal.\n",
    "\n",
    "We'll show how to update a checkpointed state below. As before, first, define your graph. We'll reuse the exact same graph as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7f9c2-fc23-4b68-b84a-a7760b5403c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# We add a node to handle the interaction with a human reviewer\n",
    "def human_review_node(state: State) -> Command[Literal[\"chatbot\", \"tools\"]]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    tool_call = last_message.tool_calls[-1]\n",
    "\n",
    "    # this is the value we'll be providing via Command(resume=<human_review>)\n",
    "    human_review = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            # Surface tool calls for review\n",
    "            \"tool_call\": tool_call,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    review_action = human_review[\"action\"]\n",
    "    review_data = human_review.get(\"data\")\n",
    "\n",
    "    # if approved, call the tool\n",
    "    if review_action == \"continue\":\n",
    "        return Command(goto=\"tools\")\n",
    "\n",
    "    elif review_action == \"feedback\":\n",
    "        # NOTE: we're adding feedback message as a ToolMessage\n",
    "        # to preserve the correct order in the message history\n",
    "        # (AI messages with tool calls need to be followed by tool call messages)\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            # This is our natural language feedback\n",
    "            \"content\": review_data,\n",
    "            \"name\": tool_call[\"name\"],\n",
    "            \"tool_call_id\": tool_call[\"id\"],\n",
    "        }\n",
    "        return Command(goto=\"chatbot\", update={\"messages\": [tool_message]})\n",
    "\n",
    "\n",
    "# Where we used tools_condition before, here we update the condition\n",
    "# to route to the human review node first, instead of tools.\n",
    "def route_after_llm(state) -> Literal[END, \"human_review_node\"]:\n",
    "    if len(state[\"messages\"][-1].tool_calls) == 0:\n",
    "        return END\n",
    "    else:\n",
    "        return \"human_review_node\"\n",
    "\n",
    "\n",
    "graph_builder.add_node(chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_node(human_review_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_after_llm,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64cc981c-38fd-4ea5-8be5-f077be796411",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00726b4b-7661-414e-a077-5cabba597163",
   "metadata": {},
   "source": [
    "We first begin a thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4124bf18-302a-4593-b485-247bfd36f150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_01NKHEFSGNmLeVGvBYDyrALi', 'input': {'query': 'LangGraph: what is it, features, and usage in AI development'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01NKHEFSGNmLeVGvBYDyrALi)\n",
      " Call ID: toolu_01NKHEFSGNmLeVGvBYDyrALi\n",
      "  Args:\n",
      "    query: LangGraph: what is it, features, and usage in AI development\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f5b9c1-e259-43f3-bfc6-f9a166a1da71",
   "metadata": {},
   "source": [
    "Note that we can read the existing state from the `graph` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b3bcae-dd04-49da-a4ef-e05634657faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_01NKHEFSGNmLeVGvBYDyrALi', 'input': {'query': 'LangGraph: what is it, features, and usage in AI development'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01NKHEFSGNmLeVGvBYDyrALi)\n",
      " Call ID: toolu_01NKHEFSGNmLeVGvBYDyrALi\n",
      "  Args:\n",
      "    query: LangGraph: what is it, features, and usage in AI development\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "existing_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf55a26-8c12-477a-9e83-5011d36ac4ee",
   "metadata": {},
   "source": [
    "So far, all of this is an _exact repeat_ of the previous section. The LLM just requested to use the search engine tool and our graph was interrupted. If we proceed as before, the tool will be called to search the web.\n",
    "\n",
    "But what if the user wants to intercede? What if we think the chat bot doesn't need to use the tool? \n",
    "\n",
    "Let's directly provide the correct response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0fd4cdb-afc4-4617-b0a9-f018232d641c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a library for building stateful, multi-actor applications with LLMs.\n",
      "\n",
      "\n",
      "Last 2 messages;\n",
      "[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='12be5dbe-75eb-45d8-8d64-5ab0c2f8555f', tool_call_id='toolu_01NKHEFSGNmLeVGvBYDyrALi'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', additional_kwargs={}, response_metadata={}, id='0f389c32-6fdd-4ad9-bd89-671d38983a70')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "answer = (\n",
    "    \"LangGraph is a library for building stateful, multi-actor applications with LLMs.\"\n",
    ")\n",
    "new_messages = [\n",
    "    # The LLM API expects some ToolMessage to match its tool call. We'll satisfy that here.\n",
    "    ToolMessage(content=answer, tool_call_id=existing_message.tool_calls[0][\"id\"]),\n",
    "    # And then directly \"put words in the LLM's mouth\" by populating its response.\n",
    "    AIMessage(content=answer),\n",
    "]\n",
    "\n",
    "new_messages[-1].pretty_print()\n",
    "graph.update_state(\n",
    "    # Which state to update\n",
    "    config,\n",
    "    # The updated values to provide. The messages in our `State` are \"append-only\", meaning this will be appended\n",
    "    # to the existing state. We will review how to update existing messages in the next section!\n",
    "    {\"messages\": new_messages},\n",
    ")\n",
    "\n",
    "print(\"\\n\\nLast 2 messages;\")\n",
    "print(graph.get_state(config).values[\"messages\"][-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584de971-6b10-4931-986e-cc35f7adbb3d",
   "metadata": {},
   "source": [
    "Now the graph is complete, since we've provided the final response message! Since state updates simulate a graph step, they even generate corresponding traces. Inspect the [LangSmith trace](https://smith.langchain.com/public/e844af02-7f45-43e2-92bc-13cd3af9b62f/r) of the `update_state` call above to see what's going on.\n",
    "\n",
    "**Notice** that our new messages are _appended_ to the messages already in the state. Remember how we defined the `State` type?\n",
    "\n",
    "```python\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "```\n",
    "\n",
    "We annotated `messages` with the pre-built `add_messages` function. This instructs the graph to always append values to the existing list, rather than overwriting the list directly. The same logic is applied here, so the messages we passed to `update_state` were appended in the same way!\n",
    "\n",
    "The `update_state` function operates as if it were one of the nodes in your graph! By default, the update operation uses the node that was last executed, but you can manually specify it below. Let's add an update and tell the graph to treat it as if it came from the \"chatbot\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d16d95c3-b465-42ac-8015-26b669d45d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1efd377d-87e6-6ab6-8003-7d963c60dd60'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(\n",
    "    config,\n",
    "    {\"messages\": [AIMessage(content=\"I'm an AI expert!\")]},\n",
    "    # Which node for this function to act as. It will automatically continue\n",
    "    # processing as if this node just ran.\n",
    "    as_node=\"chatbot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1f0056-6b6f-425f-ac1a-0d4b0e9b85cc",
   "metadata": {},
   "source": [
    "Check out the [LangSmith trace](https://smith.langchain.com/public/14edbcaf-a230-45e5-bda2-bd24a9f96cd1/r) for this update call at the provided link. **Notice** from the trace that the graph continues into the `route_after_llm` edge. We just told the graph to treat the update `as_node=\"chatbot\"`. If we follow the diagram below and start from the `chatbot` node, we naturally end up in the `route_after_llm` edge and then `__end__` since our updated message lacks tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4009ba6-dc0b-4216-ab0c-fbb104616f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cd4ffa-8fb2-4bd6-bef9-564cbfe7e3ab",
   "metadata": {},
   "source": [
    "Inspect the current state as before to confirm the checkpoint reflects our manual updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d420e813-a8c7-415d-ab31-5298d42491e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='12be5dbe-75eb-45d8-8d64-5ab0c2f8555f', tool_call_id='toolu_01NKHEFSGNmLeVGvBYDyrALi'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', additional_kwargs={}, response_metadata={}, id='0f389c32-6fdd-4ad9-bd89-671d38983a70'), AIMessage(content=\"I'm an AI expert!\", additional_kwargs={}, response_metadata={}, id='8ea38275-255a-4d64-be3c-c4fcd6c6e55a')]\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "print(snapshot.values[\"messages\"][-3:])\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380222f4-65fa-4962-afe6-6a715fadb2de",
   "metadata": {},
   "source": [
    "**Notice**: that we've continued to add AI messages to the state. Since we are acting as the `chatbot` and responding with an AIMessage that doesn't contain `tool_calls`, the graph knows that it has entered a finished state (`next` is empty).\n",
    "\n",
    "#### What if you want to **overwrite** existing messages? \n",
    "\n",
    "The [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages) function we used to annotate our graph's `State` above controls how updates are made to the `messages` key. This function looks at any message IDs in the new `messages` list. If the ID matches a message in the existing state, [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages) overwrites the existing message with the new content. \n",
    "\n",
    "As an example, let's update the tool invocation to make sure we get good results from our search engine! First, start a new thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5aa8029-927d-4597-88b7-c9fadd4f6f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search function to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_0135SrrAV1dhbeDtvKzUovUH', 'input': {'query': 'LangGraph python library for language models'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_0135SrrAV1dhbeDtvKzUovUH)\n",
      " Call ID: toolu_0135SrrAV1dhbeDtvKzUovUH\n",
      "  Args:\n",
      "    query: LangGraph python library for language models\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}  # we'll use thread_id = 2 here\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b019fc6-7826-4291-9178-6cecb5d7b3d0",
   "metadata": {},
   "source": [
    "**Next,** let's update the tool invocation for our agent. Maybe we want to search for human-in-the-loop workflows in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7215533a-b7e2-4b2d-bc1d-5122b1d06b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "Message ID run-c6d77fff-fb85-49df-ad84-07ed4e8a352c-0\n",
      "{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph python library for language models'}, 'id': 'toolu_0135SrrAV1dhbeDtvKzUovUH', 'type': 'tool_call'}\n",
      "Updated\n",
      "{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph human-in-the-loop workflow'}, 'id': 'toolu_0135SrrAV1dhbeDtvKzUovUH', 'type': 'tool_call'}\n",
      "Message ID run-c6d77fff-fb85-49df-ad84-07ed4e8a352c-0\n",
      "\n",
      "\n",
      "Tool calls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'LangGraph human-in-the-loop workflow'},\n",
       "  'id': 'toolu_0135SrrAV1dhbeDtvKzUovUH',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "snapshot = graph.get_state(config)\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "print(\"Original\")\n",
    "print(\"Message ID\", existing_message.id)\n",
    "print(existing_message.tool_calls[0])\n",
    "new_tool_call = existing_message.tool_calls[0].copy()\n",
    "new_tool_call[\"args\"][\"query\"] = \"LangGraph human-in-the-loop workflow\"\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[new_tool_call],\n",
    "    # Important! The ID is how LangGraph knows to REPLACE the message in the state rather than APPEND this messages\n",
    "    id=existing_message.id,\n",
    ")\n",
    "\n",
    "print(\"Updated\")\n",
    "print(new_message.tool_calls[0])\n",
    "print(\"Message ID\", new_message.id)\n",
    "graph.update_state(config, {\"messages\": [new_message]})\n",
    "\n",
    "print(\"\\n\\nTool calls\")\n",
    "graph.get_state(config).values[\"messages\"][-1].tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680f0ebd-ebce-4de6-8a9b-37d3d4ef0234",
   "metadata": {},
   "source": [
    "**Notice** that we've modified the AI's tool invocation to search for \"LangGraph human-in-the-loop workflow\" instead of the simple \"LangGraph\".\n",
    "\n",
    "Check out the [LangSmith trace](https://smith.langchain.com/public/0a13df28-1509-4974-9f3a-09af34671ec9/r) to see the state update call - you can see our new message has successfully updated the previous AI message.\n",
    "\n",
    "Resume the graph as before, by passing the appropriate `Command`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e9ebc73-22e8-4af2-9a36-6678873c671f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search function to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_0135SrrAV1dhbeDtvKzUovUH', 'input': {'query': 'LangGraph python library for language models'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_0135SrrAV1dhbeDtvKzUovUH)\n",
      " Call ID: toolu_0135SrrAV1dhbeDtvKzUovUH\n",
      "  Args:\n",
      "    query: LangGraph human-in-the-loop workflow\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.youtube.com/watch?v=9BPCV5TYPmg\", \"content\": \"In this video, I'll show you how to handle persistence with LangGraph, enabling a unique Human-in-the-Loop workflow. This approach allows a human to grant an\"}, {\"url\": \"https://blog.langchain.dev/human-in-the-loop-with-opengpts-and-langgraph/\", \"content\": \"TLDR; Today we're launching two \\\"human in the loop\\\" features in OpenGPTs, Interrupt and Authorize, both powered by LangGraph. We've recently launched LangGraph, a library to help developers build multi-actor, multi-step, stateful LLM applications. That's a lot words packed into a short sentence, let's take it one at a time. Multi-actor\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your patience. I've found some useful information about LangGraph, particularly focusing on its human-in-the-loop workflow capabilities. Let me summarize what I've learned:\n",
      "\n",
      "1. What is LangGraph:\n",
      "   LangGraph is a library designed to help developers build complex, stateful LLM (Large Language Model) applications. It's particularly useful for creating multi-actor and multi-step processes.\n",
      "\n",
      "2. Human-in-the-Loop Workflow:\n",
      "   One of the key features of LangGraph is its support for human-in-the-loop workflows. This means it allows for human intervention and interaction within AI-driven processes.\n",
      "\n",
      "3. OpenGPTs Integration:\n",
      "   LangGraph has been integrated with OpenGPTs, introducing two human-in-the-loop features:\n",
      "   a) Interrupt: This likely allows a human to pause or intervene in an ongoing AI process.\n",
      "   b) Authorize: This feature probably enables human approval or authorization at certain steps of the AI workflow.\n",
      "\n",
      "4. Persistence Handling:\n",
      "   LangGraph includes functionality for handling persistence. This is important for maintaining state across different steps of a workflow, especially when human interaction is involved.\n",
      "\n",
      "5. Use Cases:\n",
      "   The human-in-the-loop capabilities make LangGraph suitable for applications where you need a blend of AI efficiency and human oversight or decision-making. This could be particularly useful in fields like content moderation, complex decision processes, or scenarios where ethical considerations are important.\n",
      "\n",
      "6. Developer Focus:\n",
      "   LangGraph seems to be targeted at developers who are looking to create more sophisticated LLM applications that go beyond simple query-response models.\n",
      "\n",
      "To learn more about LangGraph, you might want to:\n",
      "1. Check out the official documentation or GitHub repository for LangGraph.\n",
      "2. Watch tutorial videos, like the one mentioned in the search results, which demonstrates how to handle persistence with LangGraph.\n",
      "3. Explore the OpenGPTs platform to see practical implementations of LangGraph's human-in-the-loop features.\n",
      "4. Try building a simple application using LangGraph to get hands-on experience with its capabilities.\n",
      "\n",
      "Would you like me to search for more specific information about any aspect of LangGraph, such as its installation process, core components, or example use cases?\n"
     ]
    }
   ],
   "source": [
    "human_command = Command(resume={\"action\": \"continue\"})\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b680b-f53f-4af2-a432-45f8c5a10779",
   "metadata": {},
   "source": [
    "Check out the [trace](https://smith.langchain.com/public/e5b0b999-b1cd-43cf-bf75-df0b35bbe366/r/1f17ded9-6958-4682-9a0d-9d7eedbf7136) to see the tool call and later LLM response. **Notice** that now the graph queries the search engine using our updated query term - we were able to manually override the LLM's search here!\n",
    "\n",
    "All of this is reflected in the graph's checkpointed memory, meaning if we continue the conversation, it will recall all the _modified_ state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "556c71d3-48ac-43d7-833c-c3f884b330a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember what I'm learning about?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Of course! You mentioned that you're learning LangGraph. I apologize for not explicitly referencing that in my response. You're right to bring that back into focus. \n",
      "\n",
      "Since you're in the process of learning LangGraph, it's important to tailor the information to your learning journey. Based on what we've found, here are some key points that might be particularly relevant for someone learning LangGraph:\n",
      "\n",
      "1. Core Concept: LangGraph is a library for building stateful, multi-step LLM applications. As you're learning it, focus on understanding how it manages state across different steps of a process.\n",
      "\n",
      "2. Human-in-the-Loop: One of LangGraph's key features is its support for human-in-the-loop workflows. This could be an interesting area to explore in your learning, as it allows you to create AI systems that can interact with humans during execution.\n",
      "\n",
      "3. Integration with OpenGPTs: Learning how LangGraph integrates with other tools like OpenGPTs could be valuable. The \"Interrupt\" and \"Authorize\" features might be good practical examples to study.\n",
      "\n",
      "4. Persistence Handling: As a learner, understanding how LangGraph handles persistence could be crucial. This relates to how the library maintains state across different steps of your AI workflows.\n",
      "\n",
      "5. Practical Application: The video mentioned in the search results about handling persistence with LangGraph could be a great resource for your learning. It seems to offer a practical demonstration, which is often very helpful when learning a new technology.\n",
      "\n",
      "To support your learning process, you might want to:\n",
      "- Start with simple LangGraph projects and gradually increase complexity\n",
      "- Focus on understanding the state management aspects of LangGraph\n",
      "- Experiment with the human-in-the-loop features to see how they work in practice\n",
      "- Look for tutorials or courses specifically designed for learning LangGraph\n",
      "\n",
      "Is there a particular aspect of LangGraph that you're finding challenging or especially interesting in your learning journey? Or would you like me to find more beginner-friendly resources for learning LangGraph?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": (\n",
    "            \"user\",\n",
    "            \"Remember what I'm learning about?\",\n",
    "        )\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5166e1b-96a6-4ac0-88a1-bf32a422134a",
   "metadata": {},
   "source": [
    "**Congratulations!** You've used `interrupt` and `update_state` to manually modify the state as a part of a human-in-the-loop workflow. Interruptions and state modifications let you control how the agent behaves. Combined with persistent checkpointing, it means you can `pause` an action and `resume` at any point. Your user doesn't have to be available when the graph interrupts!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88d4c9e-65c8-4093-a6c2-c261475f7c07",
   "metadata": {},
   "source": [
    "## Part 6: Customizing State\n",
    "\n",
    "So far, we've relied on a simple state (it's just a list of messages!). You can go far with this simple state, but if you want to define complex behavior without relying on the message list, you can add additional fields to the state. In this section, we will extend our chat bot with a new node to illustrate this.\n",
    "\n",
    "In the examples above, we involved a human deterministically: the graph __always__ interrupted whenever a tool was invoked. Suppose we wanted our chat bot to have the choice of relying on a human.\n",
    "\n",
    "One way to do this is route to the `human_review_node` only if the LLM invokes a \"human\" tool. We will include an `ask_human` flag in our graph state that we will flip if the LLM calls this tool. This is not needed for the routing process, but conveniently indicates if a run required human assistance in the output.\n",
    "\n",
    "Below, define this new graph, with an updated `State`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cf7e042-1718-4625-ae30-a9917f595449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # This flag is new\n",
    "    # highlight-next-line\n",
    "    ask_human: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87f2cb8-c066-4b54-acc4-e8c7399c5f3d",
   "metadata": {},
   "source": [
    "Next, define a schema to show the model to let it decide to request assistance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd3d704-5bee-4872-8d12-992bc970c158",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <p class=\"admonition-title\">Using Pydantic with LangChain</p>\n",
    "    <p>\n",
    "        This notebook uses Pydantic v2 <code>BaseModel</code>, which requires <code>langchain-core >= 0.3</code>. Using <code>langchain-core < 0.3</code> will result in errors due to mixing of Pydantic v1 and v2 <code>BaseModels</code>.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5192e54-6a28-42fe-a8a7-62d45d61f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"Escalate the conversation to an expert. Use this if you are unable to assist directly or if the user requires support beyond your permissions.\n",
    "\n",
    "    To use this function, relay the user's 'request' so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c1bf4-8d00-49c3-9809-ecea290fa152",
   "metadata": {},
   "source": [
    "We include this as a new tool accessible to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75cf03b1-c546-4585-8d2f-4a8be296fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "# We can bind the llm to a tool definition, a pydantic model, or a json schema\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19c61b-2087-463b-adf8-96dbc193f41c",
   "metadata": {},
   "source": [
    "Otherwise, we just update the `human_review_node` to short-circuit and route directly to `tools` if assistance is not requested. If it is requested, we flip the new flag in the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7da1212-dc9c-4385-a0a0-c4c3bc30e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "def human_review_node(state: State) -> Command[Literal[\"chatbot\", \"tools\"]]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    tool_call = last_message.tool_calls[-1]\n",
    "    \n",
    "    # highlight-next-line\n",
    "    if not tool_call[\"name\"] == RequestAssistance.__name__:\n",
    "        return Command(goto=\"tools\")\n",
    "\n",
    "    human_review = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"tool_call\": tool_call,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    review_action = human_review[\"action\"]\n",
    "    review_data = human_review.get(\"data\")\n",
    "\n",
    "    if review_action == \"continue\":\n",
    "        # highlight-next-line\n",
    "        return Command(goto=\"tools\", update={\"ask_human\": True})\n",
    "\n",
    "    elif review_action == \"feedback\":\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": review_data,\n",
    "            \"name\": tool_call[\"name\"],\n",
    "            \"tool_call_id\": tool_call[\"id\"],\n",
    "        }\n",
    "        return Command(\n",
    "            goto=\"chatbot\",\n",
    "            # highlight-next-line\n",
    "            update={\"messages\": [tool_message], \"ask_human\": True},\n",
    "        )\n",
    "\n",
    "\n",
    "def route_after_llm(state) -> Literal[END, \"human_review_node\"]:\n",
    "    if len(state[\"messages\"][-1].tool_calls) == 0:\n",
    "        return END\n",
    "    else:\n",
    "        return \"human_review_node\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca0f57-2519-49c2-9499-888b5a884897",
   "metadata": {},
   "source": [
    "Next, create the graph builder and add the chatbot and tools nodes to the graph, same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db38d3e-f2ff-4d9d-b267-27729be8e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_node(human_review_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_after_llm,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9d77f37-63cd-4ed3-86c6-ddaac62b39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b73851-810e-4466-89d8-37fba87e8494",
   "metadata": {},
   "source": [
    "The chat bot can either request help from a human (chatbot->select->human), invoke the search engine tool (chatbot->select->action), or directly respond (chatbot->select->__end__). Once an action or request has been made, the graph will transition back to the `chatbot` node to continue operations.\n",
    "\n",
    "Let's see this graph in action. We first ask it a question that requires no human intervention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00a11e0c-937d-4f11-a623-bf16ee1f6d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you search for the weather in San Francisco?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to search for the weather in San Francisco for you. To get the most up-to-date and accurate information, I'll use the search function to look this up. Let me do that for you right away.\", 'type': 'text'}, {'id': 'toolu_01QvcSUFnMXDrK4dWJ4g34P7', 'input': {'query': 'current weather in San Francisco'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01QvcSUFnMXDrK4dWJ4g34P7)\n",
      " Call ID: toolu_01QvcSUFnMXDrK4dWJ4g34P7\n",
      "  Args:\n",
      "    query: current weather in San Francisco\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1736974398, 'localtime': '2025-01-15 12:53'}, 'current': {'last_updated_epoch': 1736973900, 'last_updated': '2025-01-15 12:45', 'temp_c': 11.7, 'temp_f': 53.1, 'is_day': 1, 'condition': {'text': 'Sunny', 'icon': '//cdn.weatherapi.com/weather/64x64/day/113.png', 'code': 1000}, 'wind_mph': 5.8, 'wind_kph': 9.4, 'wind_degree': 45, 'wind_dir': 'NE', 'pressure_mb': 1025.0, 'pressure_in': 30.27, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 41, 'cloud': 0, 'feelslike_c': 10.8, 'feelslike_f': 51.4, 'windchill_c': 9.6, 'windchill_f': 49.3, 'heatindex_c': 11.1, 'heatindex_f': 51.9, 'dewpoint_c': 6.3, 'dewpoint_f': 43.3, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 2.4, 'gust_mph': 7.7, 'gust_kph': 12.4}}\"}, {\"url\": \"https://www.yahoo.com/news/january-15-2025-san-francisco-135157305.html\", \"content\": \"January 15, 2025 San Francisco Bay Area weather forecast Search query Search the web News Finance Sports Manage your account Add or switch accounts Search the web Wildfire damage from space L.A. fires underlying causes Rent hikes amid wildfires Photos: Wildfire devastation L.A. wildfires live updates KRON San Francisco January 15, 2025 San Francisco Bay Area weather forecast KRON San Francisco Wed, January 15, 2025 at 1:51 PM UTC KRON4 Meteorologist Gayle Ong has the latest Bay Area weather outlook. https://www.kron4.com/weather/san-francisco-bay-area-weather-forecast/ Solve the daily Crossword 28,373 people played the daily Crossword recently. Can you solve it faster than others?28,373 people played the daily Crossword recently. Can you solve it faster than others? Crossword Play on Yahoo Yahoo! © 2024 Yahoo.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your patience. I've searched for the current weather in San Francisco, and I have the latest information for you. Here's the weather report for San Francisco:\n",
      "\n",
      "Date and Time: January 15, 2025, 12:45 PM local time\n",
      "Temperature: 11.7°C (53.1°F)\n",
      "Condition: Sunny\n",
      "Wind: 5.8 mph (9.4 km/h), coming from the Northeast\n",
      "Humidity: 41%\n",
      "Precipitation: 0 mm (0 inches)\n",
      "Visibility: 16 km (9 miles)\n",
      "UV Index: 2.4 (low)\n",
      "\n",
      "It's a nice day in San Francisco with clear, sunny skies. The temperature is mild, typical for a winter day in the city. The wind is light, and there's no precipitation expected. It's a good day for outdoor activities, but you might want to bring a light jacket as it's not too warm.\n",
      "\n",
      "Is there anything specific about the weather you'd like to know more about?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Can you search for the weather in San Francisco?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0589f4c9-5ad9-42f0-818a-7e1fcad75517",
   "metadata": {},
   "source": [
    "This works as expected, and the state indicates that no human assistance was requested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d6e14ce-4687-48e2-a488-dca48aa9722b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"ask_human\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c0ce3-dc78-40a2-8ae2-7f4429d4bf9d",
   "metadata": {},
   "source": [
    "We next request for expert assistance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b789d334-9222-412c-83f2-0298571ce5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I need some expert guidance for building this AI agent. Could you request assistance for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I understand that you need expert guidance for building an AI agent. This is a complex topic that would benefit from specialized knowledge. I'll use the RequestAssistance function to escalate your request to an expert who can provide more in-depth support.\", 'type': 'text'}, {'id': 'toolu_01LruhQDWhxozxHJ94qDndEF', 'input': {'request': 'The user needs expert guidance for building an AI agent. They are looking for specialized knowledge and support in this area.'}, 'name': 'RequestAssistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  RequestAssistance (toolu_01LruhQDWhxozxHJ94qDndEF)\n",
      " Call ID: toolu_01LruhQDWhxozxHJ94qDndEF\n",
      "  Args:\n",
      "    request: The user needs expert guidance for building an AI agent. They are looking for specialized knowledge and support in this area.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I need some expert guidance for building this AI agent. Could you request assistance for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2dd02e-f0a6-4f63-a7d6-e49ecf40db21",
   "metadata": {},
   "source": [
    "We can respond as before, by constructing an appropriate `Command`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a91f333b-8c4d-44cb-ae6a-0a5e8ed4f23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I understand that you need expert guidance for building an AI agent. This is a complex topic that would benefit from specialized knowledge. I'll use the RequestAssistance function to escalate your request to an expert who can provide more in-depth support.\", 'type': 'text'}, {'id': 'toolu_01LruhQDWhxozxHJ94qDndEF', 'input': {'request': 'The user needs expert guidance for building an AI agent. They are looking for specialized knowledge and support in this area.'}, 'name': 'RequestAssistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  RequestAssistance (toolu_01LruhQDWhxozxHJ94qDndEF)\n",
      " Call ID: toolu_01LruhQDWhxozxHJ94qDndEF\n",
      "  Args:\n",
      "    request: The user needs expert guidance for building an AI agent. They are looking for specialized knowledge and support in this area.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: RequestAssistance\n",
      "\n",
      "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your patience. I've escalated your request, and an expert has provided some initial guidance. Here's what they recommend:\n",
      "\n",
      "The experts suggest that you look into LangGraph for building your AI agent. They mention that LangGraph is a more reliable and extensible option compared to simple autonomous agents.\n",
      "\n",
      "LangGraph is likely a framework or library designed specifically for creating advanced AI agents. It seems to offer benefits in terms of reliability and extensibility, which are crucial factors when developing complex AI systems.\n",
      "\n",
      "To follow up on this recommendation, you might want to:\n",
      "\n",
      "1. Research LangGraph to understand its features, capabilities, and how it compares to other agent-building frameworks.\n",
      "2. Look for documentation, tutorials, or guides on how to get started with LangGraph.\n",
      "3. Consider any specific requirements or goals you have for your AI agent and how LangGraph might address them.\n",
      "\n",
      "Do you have any specific questions about LangGraph or particular aspects of AI agent development that you'd like me to try to find more information about? I'd be happy to help you dig deeper into this topic.\n"
     ]
    }
   ],
   "source": [
    "human_response = (\n",
    "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
    "    \" It's much more reliable and extensible than simple autonomous agents.\"\n",
    ")\n",
    "\n",
    "human_command = Command(resume={\"action\": \"feedback\", \"data\": human_response})\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79492363-7fc6-4ec7-977d-9030648029bc",
   "metadata": {},
   "source": [
    "You can inspect the state to it's been flagged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2c94b9d-fbbd-4131-bd49-6c95d8c3708b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values[\"ask_human\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0559b-d653-4dab-8928-b001004d14cb",
   "metadata": {},
   "source": [
    "**Notice** that the chat bot has incorporated the updated state in its final response. Since **everything** was checkpointed, the \"expert\" human in the loop could perform the update at any time without impacting the graph's execution.\n",
    "\n",
    "We're almost done with the tutorial, but there is one more concept we'd like to review before finishing that connects `checkpointing` and `state updates`. \n",
    "\n",
    "This section's code is reproduced below for your reference.\n",
    "\n",
    "<details>\n",
    "<summary>Full Code</summary>\n",
    "    <pre>\n",
    "\n",
    "```python\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from pydantic import BaseModel\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # This flag is new\n",
    "    ask_human: bool\n",
    "\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"Escalate the conversation to an expert. Use this if you are unable to assist directly or if the user requires support beyond your permissions.\n",
    "\n",
    "    To use this function, relay the user's 'request' so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "def human_review_node(state: State) -> Command[Literal[\"chatbot\", \"tools\"]]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    tool_call = last_message.tool_calls[-1]\n",
    "\n",
    "    if not tool_call[\"name\"] == RequestAssistance.__name__:\n",
    "        return Command(goto=\"tools\")\n",
    "\n",
    "    human_review = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"tool_call\": tool_call,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    review_action = human_review[\"action\"]\n",
    "    review_data = human_review.get(\"data\")\n",
    "\n",
    "    if review_action == \"continue\":\n",
    "        return Command(goto=\"tools\", update={\"ask_human\": True})\n",
    "\n",
    "    elif review_action == \"feedback\":\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": review_data,\n",
    "            \"name\": tool_call[\"name\"],\n",
    "            \"tool_call_id\": tool_call[\"id\"],\n",
    "        }\n",
    "        return Command(\n",
    "            goto=\"chatbot\",\n",
    "            update={\"messages\": [tool_message], \"ask_human\": True},\n",
    "        )\n",
    "\n",
    "\n",
    "def route_after_llm(state) -> Literal[END, \"human_review_node\"]:\n",
    "    if len(state[\"messages\"][-1].tool_calls) == 0:\n",
    "        return END\n",
    "    else:\n",
    "        return \"human_review_node\"\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_node(human_review_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_after_llm,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "```\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05283db2-2f26-4800-8eda-78a4468a3d8f",
   "metadata": {},
   "source": [
    "## Part 7: Time Travel\n",
    "\n",
    "In a typical chat bot workflow, the user interacts with the bot 1 or more times to accomplish a task. In the previous sections, we saw how to add memory and a human-in-the-loop to be able to checkpoint our graph state and manually override the state to control future responses.\n",
    "\n",
    "But what if you want to let your user start from a previous response and \"branch off\" to explore a separate outcome? Or what if you want users to be able to \"rewind\" your assistant's work to fix some mistakes or try a different strategy (common in applications like autonomous software engineers)?\n",
    "\n",
    "You can create both of these experiences and more using LangGraph's built-in \"time travel\" functionality. \n",
    "\n",
    "In this section, you will \"rewind\" your graph by fetching a checkpoint using the graph's `get_state_history` method. You can then resume execution at this previous point in time.\n",
    "\n",
    "First, recall our chatbot graph. We don't need to make **any** changes from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb8a02de-a21b-4ef6-a714-7d6e44435e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from pydantic import BaseModel\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # This flag is new\n",
    "    ask_human: bool\n",
    "\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"Escalate the conversation to an expert. Use this if you are unable to assist directly or if the user requires support beyond your permissions.\n",
    "\n",
    "    To use this function, relay the user's 'request' so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "def human_review_node(state: State) -> Command[Literal[\"chatbot\", \"tools\"]]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    tool_call = last_message.tool_calls[-1]\n",
    "\n",
    "    if not tool_call[\"name\"] == RequestAssistance.__name__:\n",
    "        return Command(goto=\"tools\")\n",
    "\n",
    "    human_review = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"tool_call\": tool_call,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    review_action = human_review[\"action\"]\n",
    "    review_data = human_review.get(\"data\")\n",
    "\n",
    "    if review_action == \"continue\":\n",
    "        return Command(goto=\"tools\", update={\"ask_human\": True})\n",
    "\n",
    "    elif review_action == \"feedback\":\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": review_data,\n",
    "            \"name\": tool_call[\"name\"],\n",
    "            \"tool_call_id\": tool_call[\"id\"],\n",
    "        }\n",
    "        return Command(\n",
    "            goto=\"chatbot\",\n",
    "            update={\"messages\": [tool_message], \"ask_human\": True},\n",
    "        )\n",
    "\n",
    "\n",
    "def route_after_llm(state) -> Literal[END, \"human_review_node\"]:\n",
    "    if len(state[\"messages\"][-1].tool_calls) == 0:\n",
    "        return END\n",
    "    else:\n",
    "        return \"human_review_node\"\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_node(human_review_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_after_llm,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88faedd2-d12f-4084-9942-491f5ad8e6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5414c482-215e-4cc0-9eef-4a8722d2f468",
   "metadata": {},
   "source": [
    "Let's have our graph take a couple steps. Every step will be checkpointed in its state history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69071b02-c011-4b7f-90b1-8e89e032322d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to help you research LangGraph. To provide you with the most up-to-date and accurate information, I'll use the Tavily search engine to gather some data for you. Let me do that now.\", 'type': 'text'}, {'id': 'toolu_01FuxELYf5Jn1iXcEeduiTDs', 'input': {'query': 'LangGraph framework for language models'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01FuxELYf5Jn1iXcEeduiTDs)\n",
      " Call ID: toolu_01FuxELYf5Jn1iXcEeduiTDs\n",
      "  Args:\n",
      "    query: LangGraph framework for language models\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. ... LangChain is a framework for including AI from large language models inside data pipelines and applications. This tutorial provides an overview of what you can do with LangChain, including the problems that\"}, {\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"No. LangGraph is an orchestration framework for complex agentic systems and is more low-level and controllable than LangChain agents. LangChain provides a standard interface to interact with models and other components, useful for straight-forward chains and retrieval flows.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your patience. I've gathered some information about LangGraph for you. Let me summarize the key points:\n",
      "\n",
      "1. Purpose:\n",
      "   LangGraph is a framework designed for defining, coordinating, and executing multiple Language Model (LLM) agents or chains in a structured manner.\n",
      "\n",
      "2. Relation to LangChain:\n",
      "   While LangGraph and LangChain are related, they serve different purposes:\n",
      "   - LangChain is a framework for integrating AI from large language models into data pipelines and applications.\n",
      "   - LangGraph is more focused on orchestrating complex agentic systems.\n",
      "\n",
      "3. Level of Control:\n",
      "   LangGraph is described as more low-level and controllable compared to LangChain agents. This suggests that it offers more fine-grained control over the interaction between different components in a language model system.\n",
      "\n",
      "4. Use Cases:\n",
      "   LangGraph seems particularly useful for scenarios where you need to coordinate multiple AI agents or create more complex workflows involving language models.\n",
      "\n",
      "5. Comparison to LangChain Agents:\n",
      "   While LangChain provides a standard interface for interacting with models and components (useful for straightforward chains and retrieval flows), LangGraph appears to be more suited for building and managing more complex, multi-agent systems.\n",
      "\n",
      "If you're learning LangGraph, it might be helpful to understand:\n",
      "1. How to define and structure multiple agents or chains\n",
      "2. The ways to coordinate these agents in a cohesive system\n",
      "3. The types of complex workflows you can create with LangGraph\n",
      "4. How it differs from and complements LangChain in practical applications\n",
      "\n",
      "Would you like me to search for more specific information about any particular aspect of LangGraph, such as its key features, getting started guides, or specific use cases?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"I'm learning LangGraph. Could you do some research on it for me?\")\n",
    "        ]\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acbec099-e5d2-497f-929e-c548d7bcbf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"That's an exciting idea! Building an autonomous agent with LangGraph could be a great way to dive deep into the framework and explore its capabilities. LangGraph's focus on orchestrating complex agentic systems makes it well-suited for such a project. Let me gather some more specific information about using LangGraph for building autonomous agents.\", 'type': 'text'}, {'id': 'toolu_01TeAyyVo8fYBYApftT7yjTS', 'input': {'query': 'Building autonomous agents with LangGraph examples and tutorials'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01TeAyyVo8fYBYApftT7yjTS)\n",
      " Call ID: toolu_01TeAyyVo8fYBYApftT7yjTS\n",
      "  Args:\n",
      "    query: Building autonomous agents with LangGraph examples and tutorials\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://towardsdatascience.com/building-autonomous-multi-tool-agents-with-gemini-2-0-and-langgraph-ad3d7bd5e79d\", \"content\": \"Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph | by Youness Mansar | Jan, 2025 | Towards Data Science Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph A practical tutorial with full code examples for building and running multi-tool agents Towards Data Science LLMs are remarkable — they can memorize vast amounts of information, answer general knowledge questions, write code, generate stories, and even fix your grammar. In this tutorial, we are going to build a simple LLM agent that is equipped with four tools that it can use to answer a user’s question. This Agent will have the following specifications: Follow Published in Towards Data Science --------------------------------- Your home for data science and AI. Follow Follow Follow\"}, {\"url\": \"https://blog.futuresmart.ai/langgraph-agent-with-rag-and-nl2sql\", \"content\": \"In this blog post, we will walk you through the process of creating a custom AI agent with three powerful tools: Web Search, Retrieval-Augmented Generation (RAG), and Natural Language to SQL (NL2SQL), all integrated within the LangGraph framework. This guide is designed to provide you with a practical, step-by-step approach to building a fully functional AI agent capable of performing complex tasks such as retrieving real-time data from the web, generating responses based on retrieved information from the knowledge base, and translating natural language queries into SQL database queries. By following this tutorial, you've built an AI agent capable of performing diverse tasks such as retrieving real-time data, answering questions based on document-based knowledge, and executing SQL queries directly from natural language commands.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for sharing your interest in building an autonomous agent with LangGraph! That's an excellent way to learn and apply the framework. Based on the information I've gathered, I can provide you with some insights and guidance on how to approach this project:\n",
      "\n",
      "1. Multi-Tool Agents:\n",
      "   LangGraph allows you to create autonomous agents that can use multiple tools. This is particularly powerful for creating versatile agents that can handle a variety of tasks.\n",
      "\n",
      "2. Integration with Advanced Language Models:\n",
      "   There's an example of building autonomous multi-tool agents using Gemini 2.0 (Google's advanced language model) and LangGraph. This suggests that LangGraph is compatible with state-of-the-art language models, which can enhance your agent's capabilities.\n",
      "\n",
      "3. Practical Tutorial Available:\n",
      "   There's a practical tutorial available with full code examples for building and running multi-tool agents. This could be an excellent starting point for your project.\n",
      "\n",
      "4. Diverse Tool Integration:\n",
      "   You can equip your agent with various tools. For example, one tutorial mentions creating an agent with four different tools to answer user questions.\n",
      "\n",
      "5. Complex Task Handling:\n",
      "   LangGraph enables the creation of agents capable of performing complex tasks such as:\n",
      "   - Web searching for real-time data retrieval\n",
      "   - Implementing Retrieval-Augmented Generation (RAG) for enhanced knowledge access\n",
      "   - Using Natural Language to SQL (NL2SQL) for database interactions\n",
      "\n",
      "6. Step-by-Step Guides:\n",
      "   There are resources available that provide step-by-step approaches to building fully functional AI agents using LangGraph.\n",
      "\n",
      "7. Versatile Applications:\n",
      "   Your autonomous agent could potentially handle tasks like:\n",
      "   - Answering questions based on retrieved information from a knowledge base\n",
      "   - Executing SQL queries from natural language commands\n",
      "   - Performing web searches and integrating the results into responses\n",
      "\n",
      "To get started with your project, you might want to:\n",
      "\n",
      "1. Familiarize yourself with the LangGraph documentation and basic concepts.\n",
      "2. Follow one of the available tutorials to build a simple multi-tool agent.\n",
      "3. Define the specific tasks and capabilities you want your autonomous agent to have.\n",
      "4. Incrementally add and test new tools and functionalities to your agent.\n",
      "5. Experiment with different language models to see which works best for your use case.\n",
      "\n",
      "Would you like more information on any specific aspect of building your autonomous agent with LangGraph, such as setting up the environment, choosing tools, or handling particular types of tasks?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"Ya that's helpful. Maybe I'll build an autonomous agent with it!\")\n",
    "        ]\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e48c77-65f3-4075-8030-ebf943a281f1",
   "metadata": {},
   "source": [
    "Now that we've had the agent take a couple steps, we can `replay` the full state history to see everything that occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3e5875d-5612-41cb-8109-9a45f0282783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  8 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  7 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ('human_review_node',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('human_review_node',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182019e-bae3-4616-ba1b-f845c0ab6636",
   "metadata": {},
   "source": [
    "**Notice** that checkpoints are saved for every step of the graph. This __spans invocations__ so you can rewind across a full thread's history. We've picked out `to_replay` as a state to resume from. This is the state after the `chatbot` node in the second graph invocation above.\n",
    "\n",
    "Resuming from this point should call the **action** node next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdcf00af-8459-4132-85cc-742199391d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('human_review_node',)\n",
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efd3840-87a4-6760-8007-bd412fc24064'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8c61f5-3a4a-4cce-b81b-43fe1dcc971f",
   "metadata": {},
   "source": [
    "**Notice** that the checkpoint's config (`to_replay.config`) contains a `checkpoint_id` **timestamp**. Providing this `checkpoint_id` value tells LangGraph's checkpointer to **load** the state from that moment in time. Let's try it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5382e81-bfcd-4508-b02a-099e3d9627fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"That's an exciting idea! Building an autonomous agent with LangGraph could be a great way to dive deep into the framework and explore its capabilities. LangGraph's focus on orchestrating complex agentic systems makes it well-suited for such a project. Let me gather some more specific information about using LangGraph for building autonomous agents.\", 'type': 'text'}, {'id': 'toolu_01TeAyyVo8fYBYApftT7yjTS', 'input': {'query': 'Building autonomous agents with LangGraph examples and tutorials'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01TeAyyVo8fYBYApftT7yjTS)\n",
      " Call ID: toolu_01TeAyyVo8fYBYApftT7yjTS\n",
      "  Args:\n",
      "    query: Building autonomous agents with LangGraph examples and tutorials\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://towardsdatascience.com/building-autonomous-multi-tool-agents-with-gemini-2-0-and-langgraph-ad3d7bd5e79d\", \"content\": \"Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph | by Youness Mansar | Jan, 2025 | Towards Data Science Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph A practical tutorial with full code examples for building and running multi-tool agents Towards Data Science LLMs are remarkable — they can memorize vast amounts of information, answer general knowledge questions, write code, generate stories, and even fix your grammar. In this tutorial, we are going to build a simple LLM agent that is equipped with four tools that it can use to answer a user’s question. This Agent will have the following specifications: Follow Published in Towards Data Science --------------------------------- Your home for data science and AI. Follow Follow Follow\"}, {\"url\": \"https://github.com/anmolaman20/Tools_and_Agents\", \"content\": \"GitHub - anmolaman20/Tools_and_Agents: This repository provides resources for building AI agents using Langchain and Langgraph. This repository provides resources for building AI agents using Langchain and Langgraph. This repository provides resources for building AI agents using Langchain and Langgraph. This repository serves as a comprehensive guide for building AI-powered agents using Langchain and Langgraph. It provides hands-on examples, practical tutorials, and resources for developers and AI enthusiasts to master building intelligent systems and workflows. AI Agent Development: Gain insights into creating intelligent systems that think, reason, and adapt in real time. This repository is ideal for AI practitioners, developers exploring language models, or anyone interested in building intelligent systems. This repository provides resources for building AI agents using Langchain and Langgraph.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great idea! Building an autonomous agent with LangGraph can be an excellent way to learn the framework and explore its capabilities. Based on the information I've found, here are some insights and resources that could help you get started:\n",
      "\n",
      "1. Multi-Tool Agents:\n",
      "   LangGraph is well-suited for building autonomous agents that can use multiple tools. This allows your agent to have a variety of capabilities and choose the appropriate tool based on the task at hand.\n",
      "\n",
      "2. Integration with Other Technologies:\n",
      "   There's an example of building autonomous multi-tool agents using LangGraph in combination with Gemini 2.0 (Google's large language model). This suggests that LangGraph can be integrated with various LLMs and tools to create powerful agents.\n",
      "\n",
      "3. Practical Tutorials:\n",
      "   There are tutorials available that provide full code examples for building and running multi-tool agents. These can be extremely helpful as you start your project.\n",
      "\n",
      "4. GitHub Resources:\n",
      "   There's a GitHub repository (by user anmolaman20) that provides resources for building AI agents using both LangChain and LangGraph. This could be a valuable reference as you develop your agent.\n",
      "\n",
      "5. Capabilities:\n",
      "   The agents you can build with LangGraph can potentially memorize information, answer questions, write code, generate stories, and perform various other tasks depending on how you design them and what tools you integrate.\n",
      "\n",
      "6. Real-Time Adaptation:\n",
      "   LangGraph seems to support building agents that can think, reason, and adapt in real-time, which is crucial for truly autonomous behavior.\n",
      "\n",
      "To get started with your project, you might want to:\n",
      "\n",
      "1. Set up your development environment with LangGraph and any necessary dependencies.\n",
      "2. Start with a simple agent that uses one or two tools, then gradually increase complexity.\n",
      "3. Explore the GitHub resources and tutorials to understand best practices and common patterns in building autonomous agents with LangGraph.\n",
      "4. Consider what specific tasks or domains you want your agent to specialize in, and research appropriate tools or APIs to integrate.\n",
      "5. Experiment with different LLMs to find the one that best suits your agent's needs.\n",
      "\n",
      "Remember to consider ethical implications and potential limitations as you develop your autonomous agent. It's important to build in safeguards and ensure your agent behaves responsibly.\n",
      "\n",
      "Would you like more information on any specific aspect of building your autonomous agent with LangGraph, such as setting up the environment, choosing tools, or designing the agent's decision-making process?\n"
     ]
    }
   ],
   "source": [
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2501fed-2591-420d-98e0-4a3836fb99a8",
   "metadata": {},
   "source": [
    "Notice that the graph resumed execution from the `**action**` node. You can tell this is the case since the first value printed above is the response from our search engine tool.\n",
    "\n",
    "**Congratulations!** You've now used time-travel checkpoint traversal in LangGraph. Being able to rewind and explore alternative paths opens up a world of possibilities for debugging, experimentation, and interactive applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e584d57f-5aad-4507-815f-0b2e4b64b791",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Take your journey further by exploring deployment and advanced features:\n",
    "\n",
    "### Server Quickstart\n",
    "\n",
    "- **[LangGraph Server Quickstart](../langgraph-platform/local-server)**: Launch a LangGraph server locally and interact with it using the REST API and LangGraph Studio Web UI.\n",
    "\n",
    "### LangGraph Cloud\n",
    "\n",
    "- **[LangGraph Cloud QuickStart](../../cloud/quick_start)**: Deploy your LangGraph app using LangGraph Cloud.\n",
    "\n",
    "### LangGraph Framework\n",
    "\n",
    "- **[LangGraph Concepts](../../concepts)**: Learn the foundational concepts of LangGraph.  \n",
    "- **[LangGraph How-to Guides](../../how-tos)**: Guides for common tasks with LangGraph.\n",
    "\n",
    "### LangGraph Platform\n",
    "\n",
    "Expand your knowledge with these resources:\n",
    "\n",
    "- **[LangGraph Platform Concepts](../../concepts#langgraph-platform)**: Understand the foundational concepts of the LangGraph Platform.  \n",
    "- **[LangGraph Platform How-to Guides](../../how-tos#langgraph-platform)**: Guides for common tasks with LangGraph Platform. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
